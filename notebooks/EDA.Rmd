---
title: "EDA_2"
author: "Andrea Condado, Alejandro Perela y Miguel Calvo"
date: "20/11/2021"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(1234)
```

Primero, cargamos las librerías que vamos a necesitar a lo largo del análisis
```{r libraries, warning=FALSE, message=FALSE}
library(dplyr)
library(GGally)
library(VIM)
library(Hmisc)
library(ggplot2)
library(scales)
library(creditmodel)
library(corrplot)
library(psych)
library(caret)
library(caTools)
library(vcd)
library(pROC)
library(texreg)
```


# Definición de objetivos

El principal objetivo de este análisis es la predicción de si un cliente contratará o no el producto antes de realizar la llamada.

Para ello, vamos a analizar las diferentes variables para ver cómo es su distribución, la calidad de sus datos y cómo es la relación entre ellas.


# Diccionario
Diccionario con la definición de los diferentes campos que incluye el dataset

   1 - **age** (numeric)  
   2 - **job**: type of job (categorical: "admin.","blue-collar","entrepreneur","housemaid","management","retired","self-employed","services","student","technician","unemployed","unknown")  
   3 - **marital**: marital status (categorical: "divorced","married","single","unknown"; note: "divorced" means divorced or widowed)  
   4 - **education** (categorical: "basic.4y","basic.6y","basic.9y","high.school","illiterate","professional.course","university.degree","unknown")  
   5 - **default**: has credit in default? (categorical: "no","yes","unknown")  
   6 - **housing**: has housing loan? (categorical: "no","yes","unknown")  
   7 - **loan**: has personal loan? (categorical: "no","yes","unknown")  
   # related with the last contact of the current campaign:  
   8 - **contact**: contact communication type (categorical: "cellular","telephone")  
   9 - **month**: last contact month of year (categorical: "jan", "feb", "mar", ..., "nov", "dec")  
  10 - **day_of_week**: last contact day of the week (categorical: "mon","tue","wed","thu","fri")  
  11 - **duration**: last contact duration, in seconds (numeric). Important note:  this attribute highly affects the output target (e.g., if duration=0 then y="no"). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.  
   # other attributes:  
  12 - **campaign**: number of contacts performed during this campaign and for this client (numeric, includes last contact)  
  13 - **pdays**: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)  
  14 - **previous**: number of contacts performed before this campaign and for this client (numeric)  
  15 - **poutcome**: outcome of the previous marketing campaign (categorical: "failure","nonexistent","success")  
   # social and economic context attributes  
  16 - **emp.var.rate**: employment variation rate - quarterly indicator (numeric)  
  17 - **cons.price.idx**: consumer price index - monthly indicator (numeric)    
  18 - **cons.conf.idx**: consumer confidence index - monthly indicator (numeric)  
  19 - **euribor3m**: euribor 3 month rate - daily indicator (numeric)  
  20 - **nr.employed**: number of employees - quarterly indicator (numeric)  

  Output variable (desired target):  
  21 - **y** - has the client subscribed a term deposit? (binary: "yes","no")  


# Lectura y preparación de datos

Cargamos los datos originales para trabajar sobre ellos

```{r data_load, warning=FALSE, message=FALSE}
#folder = '/home/alejandro/Documents/Master Data Science/Curso/Fundamentos del análisis de datos/Trabajo grupo/data/bank-additional/bank-additional.csv'
data <- read.csv(file='../data/bank-additional/bank-additional-full.csv', sep=';')
head(data)
```


**Imputación de valores NA**

Una vez conocemos los diferentes valores que toman las dimensiones de nuestro dataset, sustituimos los valores unkown por NA, para poder trabajar con datos faltantes

```{r na_dimension, warning=FALSE, message=FALSE}
data$job[data$job=='unknown'] <- NA
data$marital[data$marital=='unknown'] <- NA
data$education[data$education=='unknown'] <- NA
#data$default[data$default=='unknown'] <- NA
#data$housing[data$housing=='unknown'] <- NA
#data$loan[data$loan=='unknown'] <- NA
```

## Division de datos
Separamos entre el train y test, dado que ya hemos hecho la limpieza de datos pertinente

```{r train_test, warning=FALSE, message=FALSE}
train_test = train_test_split(data, 
                              split_type = "Random", 
                              prop = 0.75)
data_train = train_test$train
data_test = train_test$test

write.csv(data_train, file='../data/data_train.csv', row.names=TRUE)
write.csv(data_test, file='../data/data_test.csv', row.names=TRUE)
```

# -------------------------------------------------------------------------------

# Lectura de datos train

Cargamos los datos train
```{r carga de datos train}
data_train<-read.csv("../data/data_train.csv", header = T, sep = ",") %>%
  subset(select = -X)
```

Comprobamos las diferentes variables, según el tipo y los primeros valores
```{r column_type, warning=FALSE, message=FALSE}
str(data_train)
```

## Modificacion del tipo de variable y reordenacion de niveles 

Modificamos las variables de tipo char a tipo factory reordenamos los niveles de las variables default, housing, loan, month y day_of_week
```{r modificacion del tipo de variable y reordenacion}
#tipo de variable
data_train$job<-as.factor(data_train$job)
data_train$marital<-as.factor(data_train$marital)
data_train$education<-as.factor(data_train$education)
data_train$default<-as.factor(data_train$default)
data_train$housing<-as.factor(data_train$housing)
data_train$loan<-as.factor(data_train$loan)
data_train$contact<-as.factor(data_train$contact)
data_train$month<-as.factor(data_train$month)
data_train$day_of_week<-as.factor(data_train$day_of_week)
data_train$poutcome<-as.factor(data_train$poutcome)
data_train$y<-as.factor(data_train$y)
   
#reordenacion
data_train$default = factor(data_train$default, levels=c('yes','no','unknown'))
data_train$housing = factor(data_train$housing, levels=c('yes','no','unknown'))
data_train$loan = factor(data_train$loan, levels=c('yes','no','unknown'))
data_train$month = factor(data_train$month, levels=c('mar','apr','may','jun','jul','aug','sep','oct','nov','dec'))
data_train$day_of_week=factor(data_train$day_of_week, levels = c('mon','thu','wed','tue','fri'))

```

Una vez que todas las columnas tienen el tipo de datos correcto, podemos continuar analizando los diferentes valores que toman las dimensiones cualitativas

# Analisis exploratorio de datos faltantes
Una vez hecho esto, visualizamos el porcentaje de valores nulos que hay en nuestros datos, así como la combinación de valores nulos entre las diferentes dimensiones

```{r na_visualization, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
aggr_plot <- aggr(data_train[,2:7], col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE,
                  labels=names(data_train[,2:7]), cex.axis=.7, gap=3, 
                  ylab=c("Histograma de datos faltantes","Patrones"))
```


# Análisis exploratorio inicial

El primer paso siempre debe consistir en efectuar un análisis exploratorio de los datos, para empezar a detectar posibles problemas.
```{r }

data_train %>% select(age,duration,campaign,pdays,previous,emp.var.rate,cons.conf.idx, cons.price.idx,euribor3m,nr.employed,y) %>%
  na.omit() %>%
  ggpairs(columns = 1:9, 
          mapping = ggplot2::aes(colour=y), 
          lower = list(continuous = "points"),
          diag = list(continuous = "densityDiag"),
          upper = list(continuous = "blank"))

train_num<- data_train %>% 
  select(age,duration,campaign,pdays,previous,emp.var.rate,cons.conf.idx, cons.price.idx,euribor3m,nr.employed)

corr <- round(cor(train_num), 1)

col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF",
                          "#77AADD","#4477AA"))
corrplot(corr, method = "shade", shade.col = NA, tl.col = "black",
         tl.srt = 50, col = col(200), addCoef.col = "black",
         order = "AOE", type = "lower", diag = F, addshade = "all") # col de colores nos expandira hasta 200 colores con las gamas usadas
```

# Transformacion de variables cuantitativas

**Días desde el contacto previo**

Antes de nada, se debe comentar que el valor 999 corresponde a gente que nunca se le ha contactado previamente.

```{r density_pdays, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=pdays, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

ggplot(data_train, aes(x=pdays, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)

ggplot(data_train %>% filter(pdays!=999), 
       aes(x=pdays, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

En este caso, parece que hay una concentración muy alta de la gente a la que no se ha contactado nunca dentro de la gente que no ha contratado. Sin embargo, si miramos a la gente que sí que contrata, podemos ver que parece que hay una concentración mayor en las personas que se les contactó entre hace 750 días y "1000" días.

Dado que si tenemos en cuenta a las personas que nunca fueron contactadas el boxplot no es interpretable, plasmamos otro filtrando para que no contengan estos registros. Y nos podemos dar cuenta de que hemos malinterpretado el gráfico de densidad, y que se debe a una alta concentración de valores que nunca han sido contactados. De acuerdo a este último boxplot, la media entre ambos grupos es muy similar, aunque para la gente que no termina contratando los datos son un poco más dispersos.


Dado que es complicado trabajar con un datos numérico de 999 cuando no significa 999, y dado que las ratios de conversión son relativamente similares cuando el valor no es 999, clasificamos a los registros en base a si han sido contactados o no. 

```{r chart_pdays_aux, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
df1 = data_train %>% group_by(y, pdays) %>% summarise(records = n(), .groups = 'drop')
ggplot(df1, aes(fill=y, y=records, x=factor(pdays))) + 
    geom_bar(position="fill", stat="identity")

df1 = data_train %>% mutate(pdays_aux = ifelse(pdays == 999,0,1))
df1 = df1 %>% group_by(y, pdays_aux) %>% summarise(records = n(), .groups = 'drop')

df2 = data_train %>% mutate(pdays_aux = ifelse(pdays == 999,0,1))
df2 = df2 %>% group_by(pdays_aux) %>% summarise(total_records = n())

df3 = df1 %>% left_join(df2, by="pdays_aux") %>% mutate(share = records/total_records)

ggplot(df3 %>% filter(y=='yes'), 
       aes(x=pdays_aux, y=share*40000)) + 
  geom_bar(df2, mapping = aes(x=pdays_aux, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)
```

Los resultados van en línea con lo esperado, teniendo una ratio de conversión más alta la gente que nunca fueron contactados en la campaña anterior 

Binarizacion de la variable pdays. Transformamos la variable numerica pdays a variable binaria que toma valores {0,1}. 
La variable vale 1 si el cliente ha sido contactado anteriormente, 0 en caso contrario
```{r pdays_aux, include=FALSE}
data_train<- data_train %>%
  mutate(pdays_aux=ifelse(pdays=="999",0,1)) 
data_train$pdays_aux<-as.factor(data_train$pdays_aux)
```


# Visualizacion de datos para EDA
## Graficos para EDA con variables cualitativas individuales

**Trabajo**

```{r histogram_job, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, job) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(job) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="job") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(job, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("job") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por trabajo")
```

Parece que los trabajos que mejor ratio de conversión tienen son las de jubilado, desempleado y estudiante, por lo que job podría ser un buen predictor. Ninguna parece estar relacionada con 
una forma activa de empleo, lo cual podría indicar la naturaleza del producto financiero ofrecido


**Estado civil**

```{r histogram_marital, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, marital) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(marital) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="marital") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(marital, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("marital") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por estado civil")
```

No hay grandes diferencias en la contratación cuando clasificamos a la gente por su estado civil


**Educación**

```{r histogram_education, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, education) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(education) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="education") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(education, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("education") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por educación")
```

La educación parece que juega también un papel importante en la predicción del éxito de la campaña, siendo university.degree y professional.course las educaciones con mejor ratio de conversión. 
Por lo que también podría ser un buen predictor


**Impago**

```{r histogram_default, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, default) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(default) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="default") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(default, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("default") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por impago")
```

El impago sí que parece un predictor relevante, dado que la gente que no tiene default tiene un ratio de conversión mejor. El valor de unknown podría justificarse con que la gente no quiere 
decir que hay tenido impagos, y estos impagos podrían implicar una menor capacidad económica y, por tanto, una menor porbabilidad de contratar un producto financiero


**Hipoteca**

```{r histogram_housing, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, housing) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(housing) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="housing") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(housing, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("housing") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por hipoteca")
```

No se aprecian diferencias en si el contactado tiene una hipoteca o no


**Préstamo**

```{r histogram_loan, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, loan) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(loan) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="loan") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(loan, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("loan") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por préstamo")
```

Tampoco parece haber diferencias teniendo en cuenta si la persona tenía un préstamo o no


**Dispositivo de contacto**

```{r histogram_contact, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, contact) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(contact) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="contact") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(contact, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("contact") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por dispositivo de contacto")
```

Parece que la forma de contactar con cada persona podría ser un buen predictor, teniendo el teléfono una  ratio de conversión 3 veces superior al teléfono fijo


**Mes de contacto**

```{r histogram_month, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, month) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(month) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="month") %>% mutate(share = records/total_records)

positions <- c("mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec")

ggplot(df3, aes(x = reorder(month, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("month") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por mes de contacto") + 
  scale_x_discrete(limits = positions)
```

El mes también parece un muy buen predictor, habiendo meses como marzo, septiembre, octubre o diciembre, con una ratio de conversión muy alta. Cabe destacar también que son los meses con un menor número de llamadas


**Día de la semana de contacto**

```{r histogram_day_of_week, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, day_of_week) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(day_of_week) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="day_of_week") %>% mutate(share = records/total_records)

positions <- c("mon", "tue", "wed", "thu", "fri")

ggplot(df3, aes(x = reorder(day_of_week, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("day_of_week") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por día de contacto") + 
  scale_x_discrete(limits = positions)
```

No parece haber ninguna influencia en el resultado de la camapaña por parte del día de la semana de contacto


**Días desde el contacto previo**

```{r histogram_pdays_aux, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, pdays_aux) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(pdays_aux) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="pdays_aux") %>% mutate(share = records/total_records)

ggplot(df3, aes(x=reorder(pdays_aux,-records),y=records, fill=y, ymax=records*1.15)) + 
  geom_bar(stat = "identity", position = "dodge") +
  xlab("pdays_aux") +
  geom_text(stat = "identity", aes(label=paste(records,"\n(", label_percent(accuracy = 1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),size=3) + 
  ggtitle("Distribucion por días desde el contacto previo")
  scale_x_discrete(limits = positions) 
  

```

Observamos que el ratio de conversión más alto es el que corresponde a la gente que nunca fue contactada en la campaña anterior, por lo que Dias desde el contacto previo puede ser un buen predictor


**Resultado de la campaña previa**

```{r histogram_poutcome, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, poutcome) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(poutcome) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="poutcome") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(poutcome, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("poutcome") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por el resultado de la campaña previa")
```

El resultado de la campaña previa también es un buen predictor


**Resultado de esta campaña**

```{r histogram_y, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y) %>% summarise(records = n())

ggplot(df1, aes(x = reorder(y, -records), y=records, fill=y, ymax=records*1.15)
                  ) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("y") +
  geom_text(stat='identity', aes(label=records), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por el resultado de esta campaña")
```


Antes de continuar con el análisis, vamos a analizar por qué hay determinadas variables que son tan relevantes, sin que haya una lógica aparente detrás de ello, como el dispositivo de contacto 
o el mes de contacto. Y trataremos de averiguar si alguna variable no es relevante por sí sola, si no que depende de otras variables, y poder así reducir variables redundantes


## Graficos para EDA con variables cuantitativas individuales

**Edad**

```{r density_age, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=age, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, age) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(age) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="age") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=age, y=share*1500)) + 
  geom_bar(df2, mapping = aes(x=age, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=2)

ggplot(data_train, aes(x=age, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Como podemos observar en la gráfica de densidad, parece que las personas que terminan contratando son ligeramente más mayores que las que no. Y de hecho, como podemos ver en el gráfico de cajas,
las edades son de media más bajas y están menos dispersas para las personas que no contratan.


**Duración de la llamada**

```{r density_duration, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=duration, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

ggplot(data_train, aes(x=duration, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

En este caso, únicamente confirmamos lo que ya sospechábamos, y es que cuanto mayor es la duración de la llamada, mayor es la proporción de personas que termina contratando. La dispersión también
es mayor en el caso de la gente que contrata


**Número de contactos durante esta campaña**

```{r density_campaign, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=campaign, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, campaign) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(campaign) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="campaign") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=campaign, y=share*80000)) + 
  geom_bar(df2, mapping = aes(x=campaign, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)

ggplot(data_train, aes(x=campaign, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Podemos ver que conforme aumentan el número de contactos, la ratio de conversión decrece, lo cual podría indicar que es un buen indicador


**Número de veces contactado antes de esta campaña**

```{r density_previous, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=previous, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, previous) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(previous) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="previous") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=previous, y=share*40000)) + 
  geom_bar(df2, mapping = aes(x=previous, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)

ggplot(data_train, aes(x=previous, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Parece que la distribución es más o menos similar para ambos grupos de personas, de acuerdo a la función de densidad. Aunque viendo el gráfico de barras apiladas y el gráfico de cajas, parece 
que hay una mayor concentración de personas que nunca han sido contactadas previamente entre la gente que nunca contrató


**Ratio de variación del empleo**

```{r density_emp_var_rate, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=emp.var.rate, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, emp.var.rate) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(emp.var.rate) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="emp.var.rate") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=emp.var.rate, y=share*25000)) + 
  geom_bar(df2, mapping = aes(x=emp.var.rate, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)

ggplot(data_train, aes(x=emp.var.rate, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Parece que cuanto más aumenta el empleo, mayor es la proporción de personas que no termina contratando, lo cual podemos confirmar con el gráfico de cajas. Cuanto más positiva es la variación 
en el empleo, menos gente contrata, lo cual podría estar relacionado con que la gente tenga menos necesidad de contratar cuando las condiciones macro son mejores


**Índice de precios al consumo**

```{r density_cons_price_idx, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=cons.price.idx, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, cons.price.idx) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(cons.price.idx) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="cons.price.idx") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=cons.price.idx, y=share*12000))  + 
  geom_bar(df2, mapping = aes(x=cons.price.idx, y=total_records), stat = "identity", fill='coral1')+
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)

ggplot(data_train, aes(x=cons.price.idx, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Si miramos la gráfica de densidad, parece que cuando hay un mayor número de registros y el índice aumenta, la ratio de conversión es peor. Es cuando el índice está en mínimos cuando la ratio 
es superior.

El gráfico de cajas parece indicar algo parecido, dado que la media del índice es ligeramente superior entre los usuarios que no terminaron contratando, aunque esta diferencia no parece muy
relevante.


**Índice de confianza del consumidor**

```{r density_cons_conf_idx, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=cons.conf.idx, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

ggplot(data_train, aes(x=cons.conf.idx, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

**Este todavía no entiendo muy bien la relación, porque parece que no hay ninguna lógica detrás**


**Euribor a 3 meses**

```{r density_euribor3m, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=euribor3m, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

ggplot(data_train, aes(x=euribor3m, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Cuanto mayor es el euribor, menor cantidad de gente contrata, y viceversa, cuanto menor es más gente contrata. Esto podría deberse a que un menor euribor implica menores intereses en el 
producto contratado. El gráfico de cajas nos arroja unos resultados similares


**Número de empleados**

```{r density_nr_employed, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=nr.employed, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, nr.employed) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(nr.employed) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="nr.employed") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=nr.employed, y=share*25000)) + 
  geom_bar(df2, mapping = aes(x=nr.employed, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)

ggplot(data_train, aes(x=nr.employed, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

A mayor número de emplados, menor es la cantidad de gente que contrata el producto, y viceversa. Esto puede deberse a que conforme mejores son las condiciones macroeconómicas, menor necesidad tiene la gente de contratar este tipo de productos


# Graficos para EDA multivariantes

## Graficos especifico para variables categoricas

**Edad & trabajo**

```{r hist_age_job, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
ggplot(data_train,aes(x=age, fill=job)) + 
  geom_bar() + 
  ggtitle ("Edad y trabajo") + 
  xlab("Edad") + 
  ylab("Trabajo") + 
  labs(fill="y")
```

Vemos que entre los 18 y los 25, la principal ocupación es la de estudiante, hasta los 55, diferentes empleos, y a partir de los 60 la de retirado. Resultados que parecen bastante lógicos.


**Edad y estado civil**

```{r hist_age_marital, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
ggplot(data_train, aes(x=age, fill=marital)) + 
  geom_bar() + 
  ggtitle ("Edad y estado civil") + 
  xlab("Edad") + 
  ylab("Estado civil") + 
  labs(fill="y") 
```

Podemos ver que entre los 18 y los 30, el estado civil predominante es el de soltero, mientras que el de casado, y después el de divorciado, son los más presentes a partir de los 30


**Edad y dispositivo de contacto**

```{r hist_age_contact, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
ggplot(data_train, aes(x=age, fill=contact)) + 
  geom_bar() + 
  ggtitle ("Edad y dispositivo de contacto") + 
  xlab("Edad") + 
  ylab("Dispositivo de contacto") + 
  labs(fill="y") 
```
 
Observamos que por edad, en torno a los 60 años hay menor ratio de conversión por contacto vía teléfono fijo y un descenso abrupto en la cantidad de contactos a personas de esa edad.


**Mes & trabajo**

```{r hist_month_job_1, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
positions <- c("mar", "sep", "oct", "dec")

ggplot(data_train,aes(x=month, fill=job)) + 
  geom_bar() + 
  ggtitle ("Marzo, Septiembre, Octubre y Diciembre: los meses con MEJOR ratio de conversión") + 
  xlab("Edad") + 
  ylab("Trabajo") + 
  labs(fill="y") + 
  scale_x_discrete(limits = positions)
```
```{r hist_month_job_2, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
positions <- c("apr", "may", "jun", "jul", "aug", "nov")

ggplot(data_train,aes(x=month, fill=job)) + 
  geom_bar() + 
  ggtitle ("Abril, Mayo, Junio, Julio, Agosto y Noviembre: los meses con PEOR ratio de conversión") + 
  xlab("Edad") + 
  ylab("Trabajo") + 
  labs(fill="y") + 
  scale_x_discrete(limits = positions)
```

Parece que la principal diferencia entre ambos grupos de meses es la menor presencia de trabajadores blue-collar en el primer grupo, con una mala ratio de conversión, y la mayor presencia de estudiantes y, sobre todo, de gente retirada.

Aún así, debería haber otros factores que afecten a la ratio de conversión tan alta que tienen, dado que es muy superior a la de cualquier trabajo. Por ello, vamos a analizar también la relación con el resultado de campañas anteriores


**Mes & resultado de la campaña previa**

```{r hist_month_poutcome, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
positions <- c("mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec")

df1 = data_train %>% group_by(month, poutcome) %>% summarise(records = n(), .groups = 'drop')
ggplot(df1, aes(fill=poutcome, y=records, x=month)) + 
  geom_bar(position="fill", stat="identity") + 
  scale_x_discrete(limits = positions)+ 
  ggtitle ("Success (65%), Failure (14%) y Nonexistent (9%) (ratios de conversión)") + 
  scale_y_continuous(labels = scales::percent)
```

Parece que también está muy influenciado porque en estos meses la proporción de contactos que en el pasado resultaron en éxito es mucho mayor. De todas formas, parece que es una combinación 
de varios factores, trabajo, éxito en pasadas campañas..., lo que ha hecho que la ratio en estos meses sea mejor


**Dispositivo de contacto & resultado de la campaña previa**

```{r hist_contact_poutcome, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
df1 = data_train %>% group_by(contact, poutcome) %>% summarise(records = n(), .groups = 'drop')
ggplot(df1, aes(fill=poutcome, y=records, x=contact)) + 
  geom_bar(position="fill", stat="identity") + 
  ggtitle ("Success (65%), Failure (14%) y Nonexistent (9%) (ratios de conversión)") + 
  scale_y_continuous(labels = scales::percent)
```

Podemos ver que success y failure tienen mayor peso en los contactado por teléfono, los cuales tienen una mejor ratio de conversión


**Dispositivo de contacto & trabajo**

```{r hist_contact_job, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
df1 = data_train %>% group_by(contact, job) %>% summarise(records = n(), .groups = 'drop')
ggplot(df1, aes(fill=job, y=records, x=contact)) + 
  geom_bar(position="fill", stat="identity") + 
  scale_y_continuous(labels = scales::percent)
```

En este caso, parecen tener mayor relevancia los trabajadores de tipo admin. y technician con una mejor ratio de conversión, y menor los de tipo blue-collar con peor ratio. Como en el caso anterior 
parece una combinación de varios facores, campaña previa, trabajo..., lo que ha provocado una diferencia en la conversión entre ambas formas de contacto


##Relación entre variables numéricas.

```{r cor_plot_numeric, fig.align='center', fig.show='hold', fig.width=12, fig.height=7}
data_trainnum <- select_if(data_train, is.numeric)
cor(data_trainnum)
corPlot(data_trainnum, cex = 0.5, main = "Matriz de correlación", upper = FALSE)
```
Las variables edad, duración y campaña son las tres variables que muestran menor correlación con el resto, por lo que pueden ser variables poco relevantes para el modelo. 

Relativo a la variable previous, observamos que es la única que muestra fundamentalmente correlaciones negativas, por lo que es relevante considerarla en el modelo futuro.


##Modelos de regresión logística

Debido a que la variable y (), es binaria, no se puede plantear la regresión lineal. Por tanto, se plantea un modelo de regresión logística.

Previo a la aplicación del modelo, convertimos los valores en 0 y 1, tanto del train como del test.


```{r}
data_train$y[which(data_train$y =="no")] <- 0
data_train$y[which(data_train$y =="yes")] <- 1
data_train$y <- as.numeric(data_train$y)
data_test$y[which(data_test$y =="no")] <- 0
data_test$y[which(data_test$y =="yes")] <- 1
data_test$y <- as.numeric(data_test$y)
``` 
#Modelos.

```{r}
m0 <- glm(y ~1, data = data_train, family = "binomial")
    
m1 <- glm(y ~ ., data = data_train, family = "binomial")
    
m2 <- step_model <- step(m0, scope = list(lower = m0, upper = m1), direction = "forward")
```
```{r}
step_prob <- predict(m2, type = "response")
    
ROC <- roc(data_train$y, step_prob)
plot(ROC, col = "red")
auc(ROC)
```
#Variables significativas del modelo completo.
```{r}
sig.var<- summary(m1)$coeff[-1,4] <0.01
names(sig.var)[sig.var == TRUE]
```

Por tanto, las variables significativas del modelo son ...

#Predicciones y matriz de confusión del modelo completo.

```{r}
predicciones <- ifelse(test = m1$fitted.values > 0.5, yes = 1, no = 0)
matriz_confusion <- table(m1$model$y, predicciones,
                          dnn = c("observaciones", "predicciones"))
matriz_confusion
```
Se observa una mejor ratio de TN que de TP. 

```{r}
mosaic(matriz_confusion, shade = T, colorize = T,
       gp = gpar(fill = matrix(c("green3", "red2", "red2", "green3"), 2, 2)))
``` 
```{r}
pred1<- predict.glm(m1,newdata = data_test, type="response")
result1<- table(data_test$y, floor(pred1+0.5))
result1
```

Realizamos la curva ROC para evaluar el AUC del modelo.

```{r}
ROC <- roc(data_test$y, pred1)
plot(ROC, col = "red")
auc(ROC)
```

El AUC tiene un valor muy adecuado. Sin embargo, analizaremos un modelo más parsimonioso que el modelo completo. 


#Modelo 3. Modelo con las variables significativas.
```{r}
m3 <- glm(y ~ job+education+default+contact+month+duration+campaign+pdays+poutcome+emp.var.rate+cons.price.idx+cons.conf.idx+nr.employed, family = binomial, data= data_train)
summary(m3)
```
```{r}
sig.var<- summary(m3)$coeff[-1,4] <0.01
names(sig.var)[sig.var == TRUE]
```

Por tanto, las variables significativas del modelo son ...

```{r}
AIC(m3)
BIC(m3)
```
#Predicciones y matriz de confusión.

```{r}
predicciones3 <- ifelse(test = m3$fitted.values > 0.5, yes = 1, no = 0)
matriz_confusion3 <- table(m3$model$y, predicciones,
                          dnn = c("observaciones", "predicciones"))
matriz_confusion3
```
Se observa una mejor ratio de TN que de TP. 

```{r}
mosaic(matriz_confusion3, shade = T, colorize = T,
       gp = gpar(fill = matrix(c("green3", "red2", "red2", "green3"), 2, 2)))
``` 
```{r}
pred3<- predict.glm(m3,newdata = data_test, type="response")
result3<- table(data_test$y, floor(pred3+0.5))
result3
```

Realizamos la curva ROC para evaluar el AUC del modelo.

```{r}
ROC3 <- roc(data_test$y, pred3)
plot(ROC3, col = "red")
auc(ROC3)
```

El AUC tiene un valor muy adecuado, muy semejante al modelo completo. 
```{r}
anova(m1)
```
```{r coef_plot, fig.align='center', fig.show='hold', fig.width=12, fig.height=7}
library(coefplot)
coefplot(m1)  + 
  theme_minimal() + 
  labs(title="Estimación de coeficientes con error estandar", 
       x="Estimación", 
       y="Variable", 
       caption="Elaboración propia")
```

```{r}
library(texreg)
htmlreg(list(m0, m1, m3), caption="Comparación de modelos logit")
```

```{r}
#m1
dev <- m1$deviance
nullDev <- m1$null.deviance
modelChi <- nullDev - dev
modelChi
chigl <- m1$df.null - m1$df.residual
chisq.prob <- 1 - pchisq(modelChi, chigl)
chisq.prob
R2.hl <- modelChi/m1$null.deviance
R2.hl
#m3
dev1 <- m3$deviance
nullDev1<- m3$null.deviance
modelChi1 <- nullDev - dev
modelChi1
chigl1 <- m3$df.null - m3$df.residual
chisq.prob1 <- 1 - pchisq(modelChi1, chigl1)
chisq.prob1
R2.hl1 <- modelChi1/m3$null.deviance
R2.hl1
```
