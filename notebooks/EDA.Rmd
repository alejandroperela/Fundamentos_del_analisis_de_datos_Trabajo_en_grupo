---
title: "Métodos de Análisis de datos"
author: "Andrea Condado, Alejandro Perela y Miguel Calvo"
date: "14/01/2022"
output:
  html_document:
    code_folding: hide
    fig_caption: yes
    latex_engine: xelatex
    number_sections: yes
    toc: TRUE
    toc_float: TRUE 
    smooth_scroll: TRUE
    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(1234)
```

Primero, cargamos las librerías que vamos a necesitar a lo largo del análisis
```{r libraries, warning=FALSE, message=FALSE}
library(dplyr)
library(GGally)
library(VIM)
library(Hmisc)
library(ggplot2)
library(scales)
library(creditmodel)
library(corrplot)
library(psych)
library(caret)
library(caTools)
library(vcd)
library(pROC)
library(texreg)
library(mice)
library(coefplot)
library(car)
library(performance)
library(see)
library(patchwork)
library(blorr)
library(ltm)
library(qgraph)
```


# Definición de objetivos

El principal objetivo de este análisis es la predicción de si un cliente contratará o no el producto antes de realizar la llamada.

Para ello, vamos a analizar las diferentes variables para ver cómo es su distribución, la calidad de sus datos y cómo es la relación entre ellas.

# Base de datos

La base de datos está basada en los datos tomados en el estudio de [Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014. Available at: [pdf] http://dx.doi.org/10.1016/j.dss.2014.03.001 

Contiene 41188 datos y 20 campos, ordenados por fecha desde mayo de 2008 a noviembre de 2010. Los datos vienen de un banco minorista de Portugal. 

# Diccionario
Diccionario con la definición de los diferentes campos que incluye el dataset.

   1 - **age** (numeric)  
   2 - **job**: type of job (categorical: "admin.","blue-collar","entrepreneur","housemaid","management","retired","self-employed","services","student","technician","unemployed","unknown")  
   3 - **marital**: marital status (categorical: "divorced","married","single","unknown"; note: "divorced" means divorced or widowed)  
   4 - **education** (categorical: "basic.4y","basic.6y","basic.9y","high.school","illiterate","professional.course","university.degree","unknown")  
   5 - **default**: has credit in default? (categorical: "no","yes","unknown")  
   6 - **housing**: has housing loan? (categorical: "no","yes","unknown")  
   7 - **loan**: has personal loan? (categorical: "no","yes","unknown")  
   # related with the last contact of the current campaign:  
   8 - **contact**: contact communication type (categorical: "cellular","telephone")  
   9 - **month**: last contact month of year (categorical: "jan", "feb", "mar", ..., "nov", "dec")  
  10 - **day_of_week**: last contact day of the week (categorical: "mon","tue","wed","thu","fri")  
  11 - **duration**: last contact duration, in seconds (numeric). Important note:  this attribute highly affects the output target (e.g., if duration=0 then y="no"). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.  
   # other attributes:  
  12 - **campaign**: number of contacts performed during this campaign and for this client (numeric, includes last contact)  
  13 - **pdays**: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)  
  14 - **previous**: number of contacts performed before this campaign and for this client (numeric)  
  15 - **poutcome**: outcome of the previous marketing campaign (categorical: "failure","nonexistent","success")  
   # social and economic context attributes  
  16 - **emp.var.rate**: employment variation rate - quarterly indicator (numeric)  
  17 - **cons.price.idx**: consumer price index - monthly indicator (numeric)    
  18 - **cons.conf.idx**: consumer confidence index - monthly indicator (numeric)  
  19 - **euribor3m**: euribor 3 month rate - daily indicator (numeric)  
  20 - **nr.employed**: number of employees - quarterly indicator (numeric)  

  Output variable (desired target):  
  21 - **y** - has the client subscribed a term deposit? (binary: "yes","no")  

Las variables 16, 17, 18, 19 y 20 no pertenecen a la muestra original y han sido extraídas de https://www.bportugal.pt/estatisticasweb.

# Lectura y preparación de datos

Cargamos los datos originales para trabajar sobre ellos.

```{r data_load, warning=FALSE, message=FALSE}
data <- read.csv(file='../data/bank-additional/bank-additional-full.csv', sep=';')
head(data)
```


**Detección de valores NA**


Una vez conocemos los diferentes valores que toman las dimensiones de nuestro dataset, sustituimos los valores unkown por NA, para poder trabajar con datos faltantes. Los datos faltantes en este caso parecen ser MNAR (missing not at random), ya que son variables que la persona conoce, pero ha decidido no contestar. También podrían ser MAR (missing at random).

```{r na_dimension, warning=FALSE, message=FALSE}
data$job[data$job=='unknown'] <- NA
data$marital[data$marital=='unknown'] <- NA
data$education[data$education=='unknown'] <- NA
#data$default[data$default=='unknown'] <- NA
#data$housing[data$housing=='unknown'] <- NA
#data$loan[data$loan=='unknown'] <- NA
```

## División de datos
Separamos entre el train y test, dado que ya hemos hecho la limpieza de datos pertinente. Los datos train serían el 75 % de la muestra, seleccionada al azar. Los datos test, por tanto, serían un 25 %.

```{r train_test, warning=FALSE, message=FALSE}
train_test = train_test_split(data, 
                              split_type = "Random", 
                              prop = 0.75)
data_train = train_test$train
data_test = train_test$test

write.csv(data_train, file='../data/data_train.csv', row.names=TRUE)
write.csv(data_test, file='../data/data_test.csv', row.names=TRUE)
```



# Lectura de datos train

Cargamos los datos train.
```{r carga de datos train}
data_train<-read.csv("../data/data_train.csv", header = T, sep = ",") %>%
  subset(select = -X)
```

Comprobamos las diferentes variables, según el tipo y los primeros valores.
```{r column_type, warning=FALSE, message=FALSE}
str(data_train)
attach(data_train)
```

## Modificación del tipo de variable y reordenación de niveles 

Modificamos las variables de tipo char a tipo factory reordenamos los niveles de las variables default, housing, loan, month y day_of_week.

```{r modificacion del tipo de variable y reordenacion}
#tipo de variable
data_train$job<-as.factor(data_train$job)
data_train$marital<-as.factor(data_train$marital)
data_train$education<-as.factor(data_train$education)
data_train$default<-as.factor(data_train$default)
data_train$housing<-as.factor(data_train$housing)
data_train$loan<-as.factor(data_train$loan)
data_train$contact<-as.factor(data_train$contact)
data_train$month<-as.factor(data_train$month)
data_train$day_of_week<-as.factor(data_train$day_of_week)
data_train$poutcome<-as.factor(data_train$poutcome)
data_train$y<-as.factor(data_train$y)
   
#reordenacion
data_train$default = factor(data_train$default, levels=c('yes','no','unknown'))
data_train$housing = factor(data_train$housing, levels=c('yes','no','unknown'))
data_train$loan = factor(data_train$loan, levels=c('yes','no','unknown'))
data_train$month = factor(data_train$month, levels=c('mar','apr','may','jun','jul','aug','sep','oct','nov','dec'))
data_train$day_of_week=factor(data_train$day_of_week, levels = c('mon','thu','wed','tue','fri'))

```

Una vez que todas las columnas tienen el tipo de datos correcto, podemos continuar analizando los diferentes valores que toman las dimensiones cualitativas.

# Análisis exploratorio de datos faltantes
Una vez hecho esto, visualizamos el porcentaje de valores nulos que hay en nuestros datos, así como la combinación de valores nulos entre las diferentes dimensiones.

```{r na_visualization, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
aggr_plot <- aggr(data_train[,2:7], col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE,
                  labels=names(data_train[,2:7]), cex.axis=.7, gap=3, 
                  ylab=c("Histograma de datos faltantes","Patrones"))
```
Las tres variables con NA son las variables educación (en torno al 4 %) y las variables trabajo y marital, ambas por debajo de 0.01 %. 

# Imputación de valores perdidos

```{r impute data_train, warning=FALSE, message=FALSE}
#cart (árbol de regresiones) es una imputación mucho más lenta que pmm (predicting mean matching)
impdata_train <- mice(data_train, m=5, maxit = 50, method = 'pmm', seed = 1234)
summary(impdata_train)
sum(is.na(impdata_train))
data_train <- mice::complete(impdata_train)
```
En estimaciones de valores perdidos, dentro de las estimaciones univariantes, encontramos varios métodos de imputación, como el árbol de regresiones o la media y la moda. Con el porcentaje de valores perdidos observados, la imputación mediante el método cart es muy lenta, por lo que se plantea la imputación mediante el método de la media.

# Análisis exploratorio inicial

El primer paso siempre debe consistir en efectuar un análisis exploratorio de los datos, para empezar a detectar posibles problemas.

```{r eda_inicial, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}

data_train %>% dplyr::select(age,duration,campaign,pdays,previous,emp.var.rate,cons.conf.idx, cons.price.idx,euribor3m,nr.employed,y) %>%
  na.omit() %>%
  ggpairs(columns = 1:9, 
          mapping = ggplot2::aes(colour=y), 
          lower = list(continuous = "points"),
          diag = list(continuous = "densityDiag"),
          upper = list(continuous = "blank"))
```


## Relación entre variables numéricas

```{r cor_plot_numeric, fig.align='center', fig.show='hold', fig.width=12, fig.height=7}
data_trainnum <- select_if(data_train, is.numeric)
cor(data_trainnum)
corPlot(data_trainnum, cex = 0.5, main = "Matriz de correlación", upper = FALSE)
qgraph(cor(data_trainnum), shape="circle", posCol="darkgreen", negCol="darkred", layout="spring", vsize=10)
```
Las variables edad, duración y campaña son las tres variables que muestran menor correlación con el resto, por lo que pueden ser variables poco relevantes para el modelo. 

Relativo a la variable previous, observamos que es la única que muestra fundamentalmente correlaciones negativas, por lo que es relevante considerarla en el modelo futuro.


# Transformación de variables cuantitativas

**Días desde el contacto previo**

Antes de nada, se debe comentar que el valor 999 corresponde a gente que nunca se le ha contactado previamente.

```{r density_pdays, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=pdays, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

ggplot(data_train, aes(x=pdays, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)

ggplot(data_train %>% filter(pdays!=999), 
       aes(x=pdays, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

En este caso, parece que hay una concentración muy alta de la gente a la que no se ha contactado nunca dentro de la gente que no ha contratado. Sin embargo, si miramos a la gente que sí que contrata, podemos ver que parece que hay una concentración mayor en las personas que se les contactó entre hace 750 días y "1000" días.

Dado que si tenemos en cuenta a las personas que nunca fueron contactadas el boxplot no es interpretable, plasmamos otro filtrando para que no contengan estos registros. Y nos podemos dar cuenta de que hemos malinterpretado el gráfico de densidad, y que se debe a una alta concentración de valores que nunca han sido contactados. De acuerdo a este último boxplot, la media entre ambos grupos es muy similar, aunque para la gente que no termina contratando los datos son un poco más dispersos.


Dado que es complicado trabajar con un datos numérico de 999 cuando no significa 999, y dado que las ratios de conversión son relativamente similares cuando el valor no es 999, clasificamos a los registros en base a si han sido contactados o no, dicotimizando la variable. 

```{r chart_pdays_aux, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
df1 = data_train %>% group_by(y, pdays) %>% summarise(records = n(), .groups = 'drop')
ggplot(df1, aes(fill=y, y=records, x=factor(pdays))) + 
    geom_bar(position="fill", stat="identity")

df1 = data_train %>% mutate(pdays_aux = ifelse(pdays == 999,0,1))
df1 = df1 %>% group_by(y, pdays_aux) %>% summarise(records = n(), .groups = 'drop')

df2 = data_train %>% mutate(pdays_aux = ifelse(pdays == 999,0,1))
df2 = df2 %>% group_by(pdays_aux) %>% summarise(total_records = n())

df3 = df1 %>% left_join(df2, by="pdays_aux") %>% mutate(share = records/total_records)

ggplot(df3 %>% filter(y=='yes'), 
       aes(x=pdays_aux, y=share*40000)) + 
  geom_bar(df2, mapping = aes(x=pdays_aux, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)
```

Los resultados van en línea con lo esperado, teniendo una ratio de conversión más alta la gente que nunca fueron contactados en la campaña anterior.

Esta binarización de la variable pdays se convertirá en la variable pdays_aux. Transformamos la variable numerica pdays a variable binaria que toma valores {0,1}. 

La variable vale 1 si el cliente ha sido contactado anteriormente, 0 en caso contrario.
```{r pdays_aux, include=FALSE}
data_train<- data_train %>%
  mutate(pdays_aux=ifelse(pdays=="999",0,1)) 
data_train$pdays_aux<-as.factor(data_train$pdays_aux)
```


# Visualización de datos para EDA
## Gráficos para EDA con variables cualitativas individuales

**Trabajo**

```{r histogram_job, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, job) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(job) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="job") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(job, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("job") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por trabajo")
```

Parece que los trabajos que mejor ratio de conversión tienen son los de jubilado, desempleado y estudiante, por lo que job podría ser un buen predictor. Ninguna parece estar relacionada con una forma activa de empleo, lo cual podría indicar la naturaleza del producto financiero ofrecido.

Gráficamente se observan diferencias significativas entre los  grupos, que será comprobado mediante un test chi-cuadrado.

```{r test chi-cuadrado 1}
tabla1<-table(y,job)
chisq.test(tabla1)
```
Se rechaza la hipótesis nula para cualquier nivel de significancia, luego consideraremos que no hay independencia entre ambas variables, es decir, hay una asociación estadísticamente significativa entre la variable trabajo y la clase y.


**Estado civil**

```{r histogram_marital, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, marital) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(marital) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="marital") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(marital, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("marital") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por estado civil")
```

No hay grandes diferencias en la contratación cuando clasificamos a la gente por su estado civil.
Para comprobar si es cierto que no hay diferencias significativas realizamos un test chi-cuadrado.

```{r test chi-cuadrado 2}
tabla<-table(y,marital)
chisq.test(tabla)
```
A pesar de lo observado en los gráficos, rechazamos la hipótesis nula para cualquier nivel de significancia. Por lo tanto, consideraremos que no hay independencia entre ambas variables, es decir, existe una asociación estadísticamente significativa entre las variables.


**Educación**

```{r histogram_education, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, education) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(education) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="education") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(education, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("education") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por educación")
```

La educación parece que juega también un papel importante en la predicción del éxito de la campaña, siendo university.degree y professional.course las educaciones con mejor ratio de conversión. Por lo que también podría ser un buen predictor.

En esta ocasión, para comprobar si es cierto que hay diferencias significativas entre la variable educación y la clase vamos a hacer un test de Fisher.

El test exacto de Fisher permite analizar si dos variables dicotómicas están asociadas cuando la muestra a estudiar es demasiado pequeña y no se cumplen las condiciones necesarias para que la aplicación del test chi-cuadrado sea adecuada.
```{r test de Fisher}
tabla<-table(y,education)
fisher.test(tabla, simulate.p.value = TRUE, B = 5000)
```
Rechazamos la hipótesis nula, luego consideraremos que no hay independencia entre ambas variables, es decir, hay una asociación estadísticamente significativa entre la educación y la clase y.


**Impago**

```{r histogram_default, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, default) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(default) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="default") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(default, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("default") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por impago")
```

El impago sí que parece un predictor relevante, dado que la gente que no tiene default tiene un ratio de conversión mejor. El valor de unknown podría justificarse con que la gente no quiere decir que hay tenido impagos, y estos impagos podrían implicar una menor capacidad económica y, por tanto, una menor porbabilidad de contratar un producto financiero.

Para comprobar si es cierto que hay diferencias significativas vamos a hacer un test de Fisher.
```{r test de Fisher 2}
tabla<-table(y,default)
#Con chi-cuadrado daba problemas por lo que uso fisher
fisher.test(tabla)
```
Rechazamos la hipotesis nula, por lo tanto, la variable default presenta una asociación significativa para la clase y.


**Hipoteca**

```{r histogram_housing, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, housing) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(housing) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="housing") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(housing, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("housing") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por hipoteca")
```

No se aprecian diferencias en si el contactado tiene una hipoteca o no.

Para comprobar si es cierto que no hay diferencias significativas realizamos un test chi-cuadrado.
```{r test chi-cuadrado 3}
tabla<-table(y,housing)
chisq.test(tabla)
chisq.test(tabla, simulate.p.value = TRUE, B = 5000)
```

A pesar de que gráficamente no se observan diferencias significativas, al realizar el test chi-cuadrado rechazamos la hipótesis nula, por lo que sí hay una asociación significativa entre la variable housing y la clase y.


**Préstamo**

```{r histogram_loan, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, loan) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(loan) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="loan") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(loan, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("loan") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por préstamo")
```

Tampoco parece haber diferencias teniendo en cuenta si la persona tenía un préstamo o no.

Para comprobar si es cierto que hay diferencias significativas vamos a hacer un test chi-cuadrado.
```{r test chi cuadrado 4}
tabla<-table(y,loan)
chisq.test(tabla)
chisq.test(tabla, simulate.p.value = TRUE, B = 5000)
```

No hay evidencias significativas para rechazar la hipótesis nula. Por lo tanto, no existen evidencias estadisticamente significativas entra la variable loan y la clase.


**Dispositivo de contacto**

```{r histogram_contact, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, contact) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(contact) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="contact") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(contact, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("contact") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por dispositivo de contacto")
```

Parece que la forma de contactar con cada persona podría ser un buen predictor, teniendo el teléfono una ratio de conversión 3 veces superior al teléfono fijo.

Para comprobar si es cierto que hay diferencias significativas realizamos el test chi-cuadrado.
```{r test chi cuadrado 5}
tabla<-table(y,contact)
chisq.test(tabla)
```
Rechazamos la hipótesis nula para cualquier nivel de significancia. La variable contact presenta una asociación estadísticamente signficativa para y.


**Mes de contacto**

```{r histogram_month, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, month) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(month) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="month") %>% mutate(share = records/total_records)

positions <- c("mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec")

ggplot(df3, aes(x = reorder(month, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("month") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por mes de contacto") + 
  scale_x_discrete(limits = positions)
```

El mes también parece un muy buen predictor, habiendo meses como marzo, septiembre, octubre o diciembre, con una ratio de conversión muy alta. Cabe destacar también que son los meses con un menor número de llamadas.

Para comprobar si es cierto que hay diferencias significativas vamos a hacer un test chi-cuadrado.
```{r test chi cuadrado 6}
tabla<-table(y,month)
chisq.test(tabla)
```
Rechazamos la hipótesis nula, es decir, la variable month muestra una asociación estadísticamente significativa con la clase y.


**Día de la semana de contacto**

```{r histogram_day_of_week, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, day_of_week) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(day_of_week) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="day_of_week") %>% mutate(share = records/total_records)

positions <- c("mon", "tue", "wed", "thu", "fri")

ggplot(df3, aes(x = reorder(day_of_week, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("day_of_week") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por día de contacto") + 
  scale_x_discrete(limits = positions)
```

No parece haber ninguna influencia en el resultado de la campaña por parte del día de la semana de contacto.

Para comprobar si es cierto que no hay diferencias significativas vamos a hacer un test chi-cuadrado.

```{r test chi cuadrado 7}
tabla<-table(y,day_of_week)
chisq.test(tabla)
```
Rechazamos la hipótesis nula para cualquier nivel de significancia, es decir, existe una asociación significativa entre el día de la semana y la clase y.


**Días desde el contacto previo**

```{r histogram_pdays_aux, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, pdays_aux) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(pdays_aux) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="pdays_aux") %>% mutate(share = records/total_records)

ggplot(df3, aes(x=reorder(pdays_aux,-records),y=records, fill=y, ymax=records*1.15)) + 
  geom_bar(stat = "identity", position = "dodge") +
  xlab("pdays_aux") +
  geom_text(stat = "identity", aes(label=paste(records,"\n(", label_percent(accuracy = 1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),size=3) + 
  ggtitle("Distribucion por días desde el contacto previo")
  scale_x_discrete(limits = positions) 
  
```

Observamos que el ratio de conversión más alto es el que corresponde a la gente que nunca fue contactada en la campaña anterior, por lo que la variable que indica si se ha contactado anteriormente con el cliente puede ser un buen predictor.

Para comprobar si es cierto que hay diferencias significativas vamos a hacer un test chi-cuadrado.
```{r test chi cuadrado 8}
tabla<-table(y,data_train$pdays_aux)
chisq.test(tabla)
```

Rechazamos la hipótesis nula. Por lo tanto, existe una asociación estadísticamente significativa entre la variable pdays_aux y la clase y.


**Resultado de la campaña previa**

```{r histogram_poutcome, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, poutcome) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(poutcome) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="poutcome") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(poutcome, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("poutcome") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por el resultado de la campaña previa")
```

El resultado de la campaña previa también puede ser un buen predictor.

Para comprobar si es cierto que hay diferencias significativas realizamos un test chi-cuadrado.
```{r test chi cuadrado 9}
tabla<-table(y,poutcome)
chisq.test(tabla)
```
Observamos que se rechaza la hipótesis nula para cualquier nivel de significancia, es decir,  poutcome presenta una asociación estadísticamente significativa con la clase.


**Resultado de esta campaña**

```{r histogram_y, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y) %>% summarise(records = n())

ggplot(df1, aes(x = reorder(y, -records), y=records, fill=y, ymax=records*1.15)
                  ) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("y") +
  geom_text(stat='identity', aes(label=records), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por el resultado de esta campaña")
```



## Gráficos para EDA con variables cuantitativas individuales

**Edad**

```{r density_age, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=age, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, age) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(age) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="age") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=age, y=share*1500)) + 
  geom_bar(df2, mapping = aes(x=age, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=2)

ggplot(data_train, aes(x=age, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Como podemos observar en la gráfica de densidad, parece que las personas que terminan contratando son ligeramente más mayores que las que no. Y de hecho, como podemos ver en el gráfico de cajas, las edades son de media más bajas y están menos dispersas para las personas que no contratan.

Para comprobar si es cierto que existen evidencias significativas realizamos el test de Student
El llamado test de Student ayuda a determinar si la diferencia observada es o no estadísticamente significativa.
```{r test de Student age}
t.test(age~y)
biserial.cor(x = age,  y = y, level = 2)
```
Observando el p-valor sí se consideraría que existen diferencias significativas entre los grupos, por tanto, la edad sí está asociado a y, aunque encontramos que la correlación es relativamente baja.


**Duración de la llamada**

```{r density_duration, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=duration, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

ggplot(data_train, aes(x=duration, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

En este caso, únicamente confirmamos lo que ya sospechábamos, y es que cuanto mayor es la duración de la llamada, mayor es la proporción de personas que termina contratando. La dispersión también es mayor en el caso de la gente que contrata.

Para comprobar si es cierto que existen evidencias significativas realizamos el test de Student.
```{r test de Student duration}
t.test(duration~y)
```
Existen diferencias significativas entre los grupos, por tanto, la duración de la última llamada sí está asociado a y.


**Número de contactos durante esta campaña**

```{r density_campaign, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=campaign, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, campaign) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(campaign) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="campaign") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=campaign, y=share*80000)) + 
  geom_bar(df2, mapping = aes(x=campaign, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)

ggplot(data_train, aes(x=campaign, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Podemos ver que conforme aumentan el número de contactos, la ratio de conversión decrece, lo cual podría indicar que es un buen indicador.

Para comprobar si es cierto que existen evidencias significativas realizamos el test de Student.
```{r}
t.test(campaign~y)
```
Rechazamos la hipótesis nula para cualquier nivel de significancia por lo que sí se consideraría que existe diferencia significativa entre los grupos. Por lo tanto, campaign sí esta asociado a y.


**Número de veces contactado antes de esta campaña**

```{r density_previous, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=previous, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, previous) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(previous) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="previous") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=previous, y=share*40000)) + 
  geom_bar(df2, mapping = aes(x=previous, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)

ggplot(data_train, aes(x=previous, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Parece que la distribución es más o menos similar para ambos grupos de personas, de acuerdo a la función de densidad. Aunque viendo el gráfico de barras apiladas y el gráfico de cajas, parece que hay una mayor concentración de personas que nunca han sido contactadas previamente entre la gente que nunca contrató.

Para comprobar si es cierto que existen evidencias significativas realizamos el test de Student.
```{r}
t.test(previous~y)
```
Se consideraría que sí existe diferencia significativa entre los grupos, es decir, previous sí está asociado a y.


**Ratio de variación del empleo**

```{r density_emp_var_rate, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=emp.var.rate, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, emp.var.rate) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(emp.var.rate) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="emp.var.rate") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=emp.var.rate, y=share*25000)) + 
  geom_bar(df2, mapping = aes(x=emp.var.rate, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)

ggplot(data_train, aes(x=emp.var.rate, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Parece que cuanto más aumenta el empleo, mayor es la proporción de personas que no termina contratando, lo cual podemos confirmar con el gráfico de cajas. Cuanto más positiva es la variación en el empleo, menos gente contrata, lo cual podría estar relacionado con que la gente tenga menos necesidad de contratar cuando las condiciones macro son mejores.

Para comprobar si es cierto que existen evidencias significativas realizamos el test de Student.
```{r}
t.test(emp.var.rate~y)
```
El p-valor es inferior a 0.05, rechazamos la hipótesis nula al considerar que sí existe diferencia significativa entre los grupos, es decir, el ratio de variación del empleo sí esta asociado a y.


**Índice de precios al consumo**

```{r density_cons_price_idx, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=cons.price.idx, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, cons.price.idx) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(cons.price.idx) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="cons.price.idx") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=cons.price.idx, y=share*12000))  + 
  geom_bar(df2, mapping = aes(x=cons.price.idx, y=total_records), stat = "identity", fill='coral1')+
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)

ggplot(data_train, aes(x=cons.price.idx, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Si miramos la gráfica de densidad, parece que cuando hay un mayor número de registros y el índice aumenta, la ratio de conversión es peor. Es decir, cuando el índice está en mínimos, la ratio es superior.

El gráfico de cajas parece indicar algo parecido, dado que la media del índice es ligeramente superior entre los usuarios que no terminaron contratando, aunque esta diferencia no parece muy relevante.

Para comprobar si es cierto que hay diferencias significativas vamos a hacer un test de Student.
```{r}
t.test(cons.price.idx~y)
```
Se consideraría que sí existe diferencia significativa entre los grupos al rechazar la hipótesis nula, por tanto, el índice de precios al consumo sí está asociado a y.


**Índice de confianza del consumidor**

```{r density_cons_conf_idx, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=cons.conf.idx, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, cons.conf.idx) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(cons.conf.idx) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="cons.conf.idx") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=cons.conf.idx, y=share*12000))  + 
  geom_bar(df2, mapping = aes(x=cons.conf.idx, y=total_records), stat = "identity", fill='coral1')+
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)

ggplot(data_train, aes(x=cons.conf.idx, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

La variable Índice de confianza del consumidor tiene un comportamiento similar a la variable Índice de precios al consumo puesto que cuando el índice está en mínimos la ratio es superior.

Para comprobar si es cierto que existen evidencias significativas realizamos el test de Student.
```{r}
t.test(cons.conf.idx~y)
```
Al rechazar la hipótesis nula se considera que sí existe diferencia significativa entre los grupos, por tanto, existe una asociación estadísticamente significativa entre el índice de confianza del consumidor y la clase y.


**Euribor a 3 meses**

```{r density_euribor3m, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=euribor3m, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

ggplot(data_train, aes(x=euribor3m, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Cuanto mayor es el euribor, menor cantidad de gente contrata, y viceversa; cuanto menor es, más gente contrata. Esto podría deberse a que un menor euribor implica menores intereses en el producto contratado. El gráfico de cajas nos arroja unos resultados similares.

Para comprobar si es cierto que existen evidencias significativas realizamos el test de Student
```{r}
t.test(euribor3m~y)
```
Rechazamos la hipótesis nula para cualquier nivel de significancia, se considera que sí existe diferencia significativa entre los grupos, por tanto, el euribor sí esta asociado a y.


**Número de empleados**

```{r density_nr_employed, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=nr.employed, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, nr.employed) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(nr.employed) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="nr.employed") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=nr.employed, y=share*25000)) + 
  geom_bar(df2, mapping = aes(x=nr.employed, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)

ggplot(data_train, aes(x=nr.employed, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

A mayor número de emplados, menor es la cantidad de gente que contrata el producto, y viceversa. Esto puede deberse a que conforme mejores son las condiciones macroeconómicas, menor necesidad tiene la gente de contratar este tipo de productos.

Para comprobar si es cierto que existen evidencias significativas realizamos el test de Student.
```{r}
t.test(nr.employed~y)
```
Se considera que sí existe diferencia significativa entre los grupos al rechazar la hipótesis nula, por tanto, el número de empleados sí está asociado a y.



# Gráficos para EDA multivariantes

A continuación, vamos a analizar por qué hay determinadas variables que son tan relevantes sin que haya una lógica aparente detrás de ello, como por ejemplo el dispositivo de contacto o el mes de contacto. Y trataremos de averiguar si alguna variable no es relevante por sí sola, sino que depende de otras variables, y poder así reducir variables redundantes.

## Gráficos específicos para variables categóricas

**Edad & trabajo**

```{r hist_age_job, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
ggplot(data_train,aes(x=age, fill=job)) + 
  geom_bar() + 
  ggtitle ("Edad y trabajo") + 
  xlab("Edad") + 
  ylab("Trabajo") + 
  labs(fill="y")
```

Vemos que entre los 18 y los 25, la principal ocupación es la de estudiante, hasta los 55, diferentes empleos, y a partir de los 60 la de retirado. Resultados que parecen bastante lógicos.


**Edad y estado civil**

```{r hist_age_marital, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
ggplot(data_train, aes(x=age, fill=marital)) + 
  geom_bar() + 
  ggtitle ("Edad y estado civil") + 
  xlab("Edad") + 
  ylab("Estado civil") + 
  labs(fill="y") 
```

Podemos ver que entre los 18 y los 30, el estado civil predominante es el de soltero, mientras que el de casado, y después el de divorciado, son los más presentes a partir de los 30


**Edad y dispositivo de contacto**

```{r hist_age_contact, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
ggplot(data_train, aes(x=age, fill=contact)) + 
  geom_bar() + 
  ggtitle ("Edad y dispositivo de contacto") + 
  xlab("Edad") + 
  ylab("Dispositivo de contacto") + 
  labs(fill="y") 
```
 
Observamos que por edad, en torno a los 60 años hay menor ratio de conversión por contacto vía teléfono fijo y un descenso abrupto en la cantidad de contactos a personas de esa edad.


**Mes & trabajo**

```{r hist_month_job_1, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
positions <- c("mar", "sep", "oct", "dec")

ggplot(data_train,aes(x=month, fill=job)) + 
  geom_bar() + 
  ggtitle ("Marzo, Septiembre, Octubre y Diciembre: los meses con MEJOR ratio de conversión") + 
  xlab("Edad") + 
  ylab("Trabajo") + 
  labs(fill="y") + 
  scale_x_discrete(limits = positions)
```
```{r hist_month_job_2, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
positions <- c("apr", "may", "jun", "jul", "aug", "nov")

ggplot(data_train,aes(x=month, fill=job)) + 
  geom_bar() + 
  ggtitle ("Abril, Mayo, Junio, Julio, Agosto y Noviembre: los meses con PEOR ratio de conversión") + 
  xlab("Edad") + 
  ylab("Trabajo") + 
  labs(fill="y") + 
  scale_x_discrete(limits = positions)
```

Parece que la principal diferencia entre ambos grupos de meses es la menor presencia de trabajadores blue-collar(clase obrera) en el primer grupo, con una mala ratio de conversión, y la mayor presencia de estudiantes y, sobre todo, de gente jubilada.

Aún así, debería haber otros factores que afecten a la ratio de conversión tan alta que tienen, dado que es muy superior a la de cualquier trabajo. Por ello, vamos a analizar también la relación con el resultado de campañas anteriores.


**Mes & resultado de la campaña previa**

```{r hist_month_poutcome, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
positions <- c("mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec")

df1 = data_train %>% group_by(month, poutcome) %>% summarise(records = n(), .groups = 'drop')
ggplot(df1, aes(fill=poutcome, y=records, x=month)) + 
  geom_bar(position="fill", stat="identity") + 
  scale_x_discrete(limits = positions)+ 
  ggtitle ("Success (65%), Failure (14%) y Nonexistent (9%) (ratios de conversión)") + 
  scale_y_continuous(labels = scales::percent)
```

Parece que también está muy influenciado porque en estos meses la proporción de contactos que en el pasado resultaron en éxito es mucho mayor. De todas formas, parece que es una combinación de varios factores, trabajo, éxito en pasadas campañas..., lo que ha hecho que la ratio en estos meses sea mejor.


**Dispositivo de contacto & trabajo**

```{r hist_contact_job, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
df1 = data_train %>% group_by(contact, job) %>% summarise(records = n(), .groups = 'drop')
ggplot(df1, aes(fill=job, y=records, x=contact)) + 
  geom_bar(position="fill", stat="identity") + 
  scale_y_continuous(labels = scales::percent)
```

En este caso, parecen tener mayor relevancia los trabajadores de tipo admin. y technician con una mejor ratio de conversión, y menor los de tipo blue-collar con peor ratio. Como en el caso anterior parece una combinación de varios factores, campaña previa, trabajo..., lo que ha provocado una diferencia en la conversión entre ambas formas de contacto.


**Dispositivo de contacto & resultado de la campaña previa**

```{r hist_contact_poutcome, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
df1 = data_train %>% group_by(contact, poutcome) %>% summarise(records = n(), .groups = 'drop')
ggplot(df1, aes(fill=poutcome, y=records, x=contact)) + 
  geom_bar(position="fill", stat="identity") + 
  ggtitle ("Success (65%), Failure (14%) y Nonexistent (9%) (ratios de conversión)") + 
  scale_y_continuous(labels = scales::percent)
```

Podemos ver que éxito y fracaso tienen mayor peso en los contactados por teléfono, los cuales tienen una mejor ratio de conversión.


# Modelos de regresión logística

Debido a que la variable y (compra o no el producto tras la llamada), es binaria, no se puede plantear la regresión lineal. Por tanto, se plantea un modelo de regresión logística.

Previo a la aplicación del modelo, dicotomizamos la variable, convirtiendo los valores en 0 y 1, tanto del train como del test.

En el test hay que incluir la variable pdays_aux, tal y como se hizo con el data_train.

```{r test_pdays_aux}
df1 = data_test %>% group_by(y, pdays) %>% summarise(records = n(), .groups = 'drop')
data_test = data_test %>% mutate(pdays_aux = ifelse(pdays == 999,0,1))
```


## Análisis exploratorio de datos faltantes
Una vez hecho esto, visualizamos el porcentaje de valores nulos que hay en nuestros datos, así como la combinación de valores nulos entre las diferentes dimensiones.

```{r na_visualization data_test, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
aggr_plot <- aggr(data_test[,2:7], col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE,
                  labels=names(data_test[,2:7]), cex.axis=.7, gap=3, 
                  ylab=c("Histograma de datos faltantes","Patrones"))
```
Las tres variables con NA son semejantes a los del data_train teniendo las variables educación un valor en torno al 4 % y las variables trabajo y marital, ambas por debajo de 0.01 %. 

## Imputación de valores perdidos

```{r impute data_test, warning=FALSE, message=FALSE}
#cart (árbol de regresiones) es una imputación mucho más lenta que pmm (predicting mean matching)
impdata_test <- mice(data_test, m=5, maxit = 50, method = 'pmm', seed = 1234)
summary(impdata_test)
sum(is.na(impdata_test))
data_test <- mice::complete(impdata_test)
```

```{r}
data_train$y <- as.numeric(data_train$y)
data_train$y[which(data_train$y =="1")] <- 0
data_train$y[which(data_train$y =="2")] <- 1
``` 

```{r}
data_test$y[which(data_test$y =="no")] <- 0
data_test$y[which(data_test$y =="yes")] <- 1
data_test$y <- as.numeric(data_test$y)
```

Comenzaremos con técnicas automáticas de selección de variables, para ver qué variables parecen aumentar o reducir los índices de ajuste.

## Técnicas automáticas de selección de variables

**Bidirectional elimination**
```{r}
#data_train1 <- na.omit(data_train)
data_train2 <- data_train[,-11] #borramos la variable duración
data_train2 <- data_train2[,-12] #borramos la variable pdays ya que usaremos pdays_aux
m0 <- glm(y~1, data = data_train2, family = "binomial")
m1 <- glm(y~., data = data_train2, family = "binomial")
regboth <- step(m0, scope = list(lower=m0, upper=m1),direction = "both"); summary(regboth)
```
Se omiten los NA porque produce errores. Este método parte del modelo predictivo sin variables (m0) y termina en el modelo completo (m1).

La duración de la llamada no se considera relevante, ya que se obtiene después de haber realizado la transacción. Esta variable, al tener una alta correlación con la variable de salida, infraestima los valores de error y sobrestima el ajuste. 

Las variables relevantes serían número de empleados, meses, resultado de la campaña previa, vía de contacto, día de la semana, trabajo, días desde el contacto previo (dicotomizada), indice de confianza del consumidor, impago, ratio de variación de empleo e índice de precios al consumo.


```{r}
reg1 <- glm(formula = y ~ nr.employed + month + poutcome + contact + 
    day_of_week + job + cons.conf.idx + campaign + default + 
    emp.var.rate + cons.price.idx, family = "binomial", data = data_train2)
```

Por tanto, el modelo reg1 será el modelo automático formado por el método stepwise.

Se plantean además, que se combinarán de manera manual, los métodos formward (hacia delante, añadiendo las variables significativas) y backward (hacia atrás), quitando las variables menos significativas.

**Forward Stepwise**
```{r}
regfit_fwd <- leaps::regsubsets(y~., data_train2, method="forward")
for (metric in c("r2", "adjr2", "Cp", "bic")){plot(regfit_fwd, scale=metric)}
```

Las variables relevantes para obtener el modelo con mejor ajuste y redimiento obtenidas por el método forward serían contacto telefónico, mes (mayo, septiembre y noviembre), resultado de la campaña previa, ratio de variación de empleo, euribor y número de empleados.


**Backward Stepwise**
```{r}
regfit_bwd <- leaps::regsubsets(y~., data_train2, method="backward")
for (metric in c("r2", "adjr2", "Cp", "bic")){plot(regfit_bwd, scale=metric)}
```
Las variables relevantes para obtener el modelo con mejor ajuste y redimiento obtenidas por el método backward serían mes (abril, mayo, junio, julio y noviembre), resultado de la campaña previa, la ratio de variación del empleo, índice de confianza del consumidor y el euribor. 


Ambos métodos sugieren como variables relevantes comunes el mes y el resultado de la campaña previa, la  ratio de variación de empleo y el euribor.

## Modelos

```{r}
#m0 <- glm(y ~1, data = data_train, family = "binomial")
m1 <- glm(y ~ ., data = data_train2, family = "binomial")

```

El modelo 1 corresponde al modelo con todas las variables.

*Variables significativas del modelo completo*
```{r}
sig.var<- summary(m1)$coeff[-1,4] <0.01
names(sig.var)[sig.var == TRUE]
```


Por tanto, las variables significativas del modelo son el trabajo (jubilado), dispositivo de contacto (teléfono), mes de contacto (abril, mayo, junio, julio, agosto, septiembre, octubre, noviembre y diciembre), día de la semana de contacto (martes, miércoles, jueves y viernes), número de campañas previas, resultado de la campaña, ratio de variación de empleo, índice de precios al consumo, índice de confianza del consumidor y el número de empleados.

```{r model 2 to 6}
m2 <- glm(y ~ age, data = data_train2, family = "binomial")
m3 <- glm(y ~ emp.var.rate, data = data_train2, family = "binomial")
#modelo forward
m4 <- glm(y ~ contact+month+poutcome+emp.var.rate+cons.conf.idx+euribor3m+nr.employed, data = data_train2, family = "binomial")
#modelo backward
m5 <- glm(y ~ month+poutcome+emp.var.rate+cons.price.idx+euribor3m, data = data_train2, family = "binomial")
#modelo comunes back y forward.
m6 <- glm(y ~ month+poutcome+emp.var.rate+euribor3m, data = data_train2, family = "binomial")
```

Los modelos 2 y 3 son modelos univariantes con la variable que menos correlaciona (edad) y la que más correlaciona con el resto (ratio de variación de empleo).

El modelo 4 y 5 corresponden a los métodos automáticos de forward y backward. l mes y el resultado de la campaña previa, la  ratio de variación de empleo y el euribor. 

El modelo 6 corresponde a las variables comunes entre los métodos automáticos de forward y backward.

```{r model 7}
m7 <- glm(y ~ job+contact+month+day_of_week+campaign+poutcome+emp.var.rate+cons.price.idx+cons.conf.idx+nr.employed, family = binomial, data=data_train2)
```

El modelo 7 recoge todas las variables significativas del modelo completo. 

```{r model 8}
m8 <- glm(y ~ default+contact+month+pdays_aux+campaign+poutcome+emp.var.rate+cons.price.idx+cons.conf.idx+nr.employed+euribor3m, family = binomial, data=data_train2)
```

El modelo 8 recoge las variables significativas de manera manual. 

**Supuestos de partida para regresión**

Obtenemos la homogeneidad de la varianza, la colinealidad y la normalidad de los residuos, ya que son los supuestos de partida para aplicar la regresión logística.

```{r}
#check_model(m0)
check_model(reg1)
check_model(m1)
check_model(m2)
check_model(m3)
```

El modelo reg1 muestra valores de colinealidad altos, y valores adecuados de leverage, ya que Los puntos se encuentran en los modelos dentro del intervalo marcado por la distancia D de Cook. El modelo 1 tiene valores muy altos de colinealidad, coherente con el uso de variables muy correlacionadas como mencionamos previamente. Los valores de leverage son semejantes al del modelo reg1.

Los modelos 2 y 3 no muestra la gráfica de colinealidad por tener un solo predictor. Ninguno de estos 4 modelos muestra valores adecuados en la normalidad de los residuos, en el gráfico Q-Q. 

```{r}
check_model(m4)
check_model(m5)
check_model(m6)
check_model(m7)
check_model(m8)
```
Los modelos 4,5,6,7 y 8 muestran valores altos de colinealidad, aumentando el riesgo de sesgo. Se observa un mejor ajuste a la distancia D de Cook en leverage, así como un gráfico Q-Q mejor que los modelos previos. Sigue habiendo una amplia distorsión en los cuartiles centrales. 

```{r}
compare_performance(reg1,m1,m2,m3,m4,m5,m6,m7,m8)
``` 

Los modelos muestran valores altos de AIC y BIC en general, siendo índices de ajuste de parsimonia, sancionando modelos que requieren un mayor número de variables. Todos los modelos (menos el 2 y el 3, que corresponden a una sola variable predictora) muestran ajustes similares, siendo el mejor el modelo 7, que incluye las variables significativas del modelo completo. 

Este modelo tiene un AIC y un BIC semejante al modelo 1, además de un valor ligeramente superior al resto de $R^2$ de Tjur y mismo valor de RMSE, que indica el error cuadrático medio.


```{r compare models 1}
plot(compare_performance(reg1,m1,m2,m3,m4, rank = TRUE))
```

```{r compare models 2}
plot(compare_performance(m5,m6,m7,m8, rank = TRUE))
```

Gráficamente, podemos evaluar que cuanto más cercano del centro, mejor rendimiento muestra. El objetivo es reducir AIC, BIC y RMSE y aumentar el $R^2$. Por tanto observamos que es el modelo 7 el que muestra mejor ajuste, aunque esto no implica que sea bueno.

### Modelo 1. Modelo completo

```{r}
Box.test(residuals(m1),type="Ljung-Box")
```
Hay presencia de autocorrelación, lo que podría sesgar el modelo.


*Predicciones y matriz de confusión del modelo completo (m1)*

```{r}
predicciones <- ifelse(test = m1$fitted.values > 0.5, yes = 1, no = 0)
matriz_confusion <- table(m1$model$y, predicciones,
                          dnn = c("observaciones", "predicciones"))
matriz_confusion
```

```{r}
TN <- matriz_confusion[1,1]
FP <- matriz_confusion[1,2]
FN <- matriz_confusion[2,1]
TP <- matriz_confusion[2,2]
```

Se observa una mejor ratio de TN que de TP.

*Medidas de clasificación del modelo completo (m1)*

```{r}
precision <- TP/(TP+FP)
recall <- TP/(TP+FN)
F1 <- 2*(precision*recall)/(precision+recall)
accuracy <- (TP+TN)/(TP+TN+FP+FN)
tabla1 <- matrix(data = c(precision,recall,F1,accuracy), ncol=1, nrow=4)
rownames(tabla1) <- c("Precision","Recall","F1","Accuracy")
tabla1
```
Los valores de precisión, exhaustividad, F1 son bastante bajos, frente a la exactitud que se muestra adecuada.

```{r}
mosaic(matriz_confusion, shade = T, colorize = T,
       gp = gpar(fill = matrix(c("green3", "red2", "red2", "green3"), 2, 2)))
``` 

```{r}
data_test$pdays_aux <- as.factor(data_test$pdays_aux)
pred1<- predict.glm(m1,newdata = data_test, type="response")
result1<- table(data_test$y, floor(pred1+0.5))
result1
```

*Evaluación del modelo completo (m1)*

**Curva ROC**

Realizamos la curva ROC para evaluar el AUC del modelo.

```{r}
ROC <- roc(data_test$y, pred1)
plot(ROC, col = "red")
auc(ROC)
logistic_gains_table1 <- blr_gains_table(m1, data = data_train)
blr_roc_curve(logistic_gains_table1)
```

El AUC tiene un valor muy adecuado, por encima de 0.80. Sin embargo, analizaremos un modelo más parsimonioso que el modelo completo. 

**Lift chart y KS Chart**

```{r}
logistic_gains_table <- blr_gains_table(m1, data = data_train2)
blr_decile_lift_chart(logistic_gains_table)
blr_ks_chart(logistic_gains_table)
```
El lift chart muestra la efectividad del modelo por deciles, estando mejor ajustado en los primeros dos deciles. El KS chart muestra una estructura similar a la curva ROC.

### Modelo final seleccionado. Modelo 7

```{r}
Box.test(residuals(m7),type="Ljung-Box")
```
Hay presencia de autocorrelación, lo que podría sesgar el modelo.


*Predicciones y matriz de confusión del modelo final (m7)*

```{r}
predicciones1 <- ifelse(test = m7$fitted.values > 0.5, yes = 1, no = 0)
matriz_confusion1 <- table(m7$model$y, predicciones1,
                          dnn = c("observaciones", "predicciones"))
matriz_confusion1
```

```{r}
TN1 <- matriz_confusion1[1,1]
FP1 <- matriz_confusion1[1,2]
FN1 <- matriz_confusion1[2,1]
TP1 <- matriz_confusion1[2,2]
```

Se observa una mejor ratio de TN que de TP.

*Medidas de clasificación*
```{r}
precision1 <- TP1/(TP1+FP1)
recall1 <- TP1/(TP1+FN1)
F11 <- 2*(precision1*recall1)/(precision1+recall1)
accuracy1 <- (TP1+TN1)/(TP1+TN1+FP1+FN1)
tabla11 <- matrix(data = c(precision1,recall1,F11,accuracy1), ncol=1, nrow=4)
rownames(tabla11) <- c("Precision","Recall","F1","Accuracy")
tabla11
```
Los valores de precisión, exhaustividad, F1 son bastante bajos, frente a la exactitud que se muestra adecuada. En comparación como el modelo 1, se obtienen valores similares.

```{r}
mosaic(matriz_confusion1, shade = T, colorize = T,
       gp = gpar(fill = matrix(c("green3", "red2", "red2", "green3"), 2, 2)))
``` 

```{r}
pred11<- predict.glm(m7,newdata = data_test, type="response")
result11<- table(data_test$y, floor(pred11+0.5))
result11
```

**Curva ROC**

Realizamos la curva ROC para evaluar el AUC del modelo.

```{r}
ROC1 <- roc(data_test$y, pred11)
plot(ROC1, col = "red")
auc(ROC1)
logistic_gains_table11 <- blr_gains_table(m7, data = data_train2)
blr_roc_curve(logistic_gains_table11)
```

El AUC tiene un valor semejante al modelo completo.

**Lift chart y KS Chart**

```{r}
logistic_gains_table1 <- blr_gains_table(m7, data = data_train2)
blr_decile_lift_chart(logistic_gains_table1)
blr_ks_chart(logistic_gains_table1)
```
El lift chart muestra mejor ajuste en el primer decil. El KS se mantiene semejante al modelo completo.

***Conclusiones del ajuste*** 

El ajuste en general, así como las predicciones han de ser tomadas con cautela debido a los supuestos de partida de la regresión logística.

Los modelos de regresión logística muestran un ajuste pobre, quedando claro que la variable duración aumenta articialmente el ajuste. En general, el modelo completo de variables significativas (m7) es el modelo que ajusta mejor, pero no habiendo una gran ganancia comparativa en el ajuste frente al modelo 1 y al resto que incluyen más de una variable.  

Con otros modelos obtenemos valores ligeramente peores, pero son mucho más parsimoniosos. 

# Conclusiones del trabajo

La imputación de los valores perdidos no ha mostrado una gran significación debido a que eran variables poco relevantes a seleccionar que finalmente no fueron incluidas en e modelo final. Las predicciones han sido poco ajustadas, pero se han podido localizar las variables relevantes. 

En general, las variables sociodemográficas no han parecido relevantes para los modelos finales, frente a las variables macroeconómicas. Tal como se planteaba inicialmente, las variables de edad, duración y campaña, han sido de las menos relevantes y menos significativas para los modelos. Finalmente que hubiera campaña previa no ha sido relevante para el modelo seleccionado. La variable educativa no fue un predictor adecuado, por lo que se descartó. 

El mes en el que se realizaron las llamadas ha sido un predictor relevante en todos los modelos, así como la ratio de empleo, el resultado de las campañas previas o el euribor. 

