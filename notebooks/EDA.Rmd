---
title: "Métodos de Análisis de datos"
author: "Andrea Condado, Alejandro Perela y Miguel Calvo"
date: "08/01/2022"
output:
  html_document:
    code_folding: hide
    fig_caption: yes
    latex_engine: xelatex
    number_sections: yes
    toc: TRUE
    toc_float: TRUE 
    smooth_scroll: TRUE
    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(1234)
```

Primero, cargamos las librerías que vamos a necesitar a lo largo del análisis
```{r libraries, warning=FALSE, message=FALSE}
library(dplyr)
library(GGally)
library(VIM)
library(Hmisc)
library(ggplot2)
library(scales)
library(creditmodel)
library(corrplot)
library(psych)
library(caret)
library(caTools)
library(vcd)
library(pROC)
library(texreg)
library(mice)
library(coefplot)
library(car)
library(performance)
library(see)
library(patchwork)
library(blorr)
library(ltm)
```


# Definición de objetivos

El principal objetivo de este análisis es la predicción de si un cliente contratará o no el producto antes de realizar la llamada.

Para ello, vamos a analizar las diferentes variables para ver cómo es su distribución, la calidad de sus datos y cómo es la relación entre ellas.

# Base de datos

La base de datos está basada en los datos tomados en el estudio de [Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014.

Contiene 41188 datos y 20 campos, ordenados por fecha desde mayo de 2008 a noviembre de 2010. Los datos vienen de un banco minoritario/personal de Portugal. 

# Diccionario
Diccionario con la definición de los diferentes campos que incluye el dataset

   1 - **age** (numeric)  
   2 - **job**: type of job (categorical: "admin.","blue-collar","entrepreneur","housemaid","management","retired","self-employed","services","student","technician","unemployed","unknown")  
   3 - **marital**: marital status (categorical: "divorced","married","single","unknown"; note: "divorced" means divorced or widowed)  
   4 - **education** (categorical: "basic.4y","basic.6y","basic.9y","high.school","illiterate","professional.course","university.degree","unknown")  
   5 - **default**: has credit in default? (categorical: "no","yes","unknown")  
   6 - **housing**: has housing loan? (categorical: "no","yes","unknown")  
   7 - **loan**: has personal loan? (categorical: "no","yes","unknown")  
   # related with the last contact of the current campaign:  
   8 - **contact**: contact communication type (categorical: "cellular","telephone")  
   9 - **month**: last contact month of year (categorical: "jan", "feb", "mar", ..., "nov", "dec")  
  10 - **day_of_week**: last contact day of the week (categorical: "mon","tue","wed","thu","fri")  
  11 - **duration**: last contact duration, in seconds (numeric). Important note:  this attribute highly affects the output target (e.g., if duration=0 then y="no"). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.  
   # other attributes:  
  12 - **campaign**: number of contacts performed during this campaign and for this client (numeric, includes last contact)  
  13 - **pdays**: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)  
  14 - **previous**: number of contacts performed before this campaign and for this client (numeric)  
  15 - **poutcome**: outcome of the previous marketing campaign (categorical: "failure","nonexistent","success")  
   # social and economic context attributes  
  16 - **emp.var.rate**: employment variation rate - quarterly indicator (numeric)  
  17 - **cons.price.idx**: consumer price index - monthly indicator (numeric)    
  18 - **cons.conf.idx**: consumer confidence index - monthly indicator (numeric)  
  19 - **euribor3m**: euribor 3 month rate - daily indicator (numeric)  
  20 - **nr.employed**: number of employees - quarterly indicator (numeric)  

  Output variable (desired target):  
  21 - **y** - has the client subscribed a term deposit? (binary: "yes","no")  

Las variables 16, 17, 18, 19 y 20 no pertenecen a la muestra original y han sido extraídas de https://www.bportugal.pt/estatisticasweb.

# Lectura y preparación de datos

Cargamos los datos originales para trabajar sobre ellos

```{r data_load, warning=FALSE, message=FALSE}
data <- read.csv(file='../data/bank-additional/bank-additional-full.csv', sep=';')
head(data)
```


**Detección de valores NA**


Una vez conocemos los diferentes valores que toman las dimensiones de nuestro dataset, sustituimos los valores unkown por NA, para poder trabajar con datos faltantes. Los datos faltantes en este caso parecen ser MNAR (missing not at random), ya que son variables que la persona conoce, pero ha decidido no contestar. También podrían ser MAR (missing at random)

```{r na_dimension, warning=FALSE, message=FALSE}
data$job[data$job=='unknown'] <- NA
data$marital[data$marital=='unknown'] <- NA
data$education[data$education=='unknown'] <- NA
#data$default[data$default=='unknown'] <- NA
#data$housing[data$housing=='unknown'] <- NA
#data$loan[data$loan=='unknown'] <- NA
```

## División de datos
Separamos entre el train y test, dado que ya hemos hecho la limpieza de datos pertinente

```{r train_test, warning=FALSE, message=FALSE}
train_test = train_test_split(data, 
                              split_type = "Random", 
                              prop = 0.75)
data_train = train_test$train
data_test = train_test$test

write.csv(data_train, file='../data/data_train.csv', row.names=TRUE)
write.csv(data_test, file='../data/data_test.csv', row.names=TRUE)
```



# Lectura de datos train

Cargamos los datos train
```{r carga de datos train}
data_train<-read.csv("../data/data_train.csv", header = T, sep = ",") %>%
  subset(select = -X)
```

Comprobamos las diferentes variables, según el tipo y los primeros valores
```{r column_type, warning=FALSE, message=FALSE}
str(data_train)
attach(data_train)
```

## Modificación del tipo de variable y reordenación de niveles 

Modificamos las variables de tipo char a tipo factory reordenamos los niveles de las variables default, housing, loan, month y day_of_week
```{r modificacion del tipo de variable y reordenacion}
#tipo de variable
data_train$job<-as.factor(data_train$job)
data_train$marital<-as.factor(data_train$marital)
data_train$education<-as.factor(data_train$education)
data_train$default<-as.factor(data_train$default)
data_train$housing<-as.factor(data_train$housing)
data_train$loan<-as.factor(data_train$loan)
data_train$contact<-as.factor(data_train$contact)
data_train$month<-as.factor(data_train$month)
data_train$day_of_week<-as.factor(data_train$day_of_week)
data_train$poutcome<-as.factor(data_train$poutcome)
data_train$y<-as.factor(data_train$y)
   
#reordenacion
data_train$default = factor(data_train$default, levels=c('yes','no','unknown'))
data_train$housing = factor(data_train$housing, levels=c('yes','no','unknown'))
data_train$loan = factor(data_train$loan, levels=c('yes','no','unknown'))
data_train$month = factor(data_train$month, levels=c('mar','apr','may','jun','jul','aug','sep','oct','nov','dec'))
data_train$day_of_week=factor(data_train$day_of_week, levels = c('mon','thu','wed','tue','fri'))

```

Una vez que todas las columnas tienen el tipo de datos correcto, podemos continuar analizando los diferentes valores que toman las dimensiones cualitativas

# Análisis exploratorio de datos faltantes
Una vez hecho esto, visualizamos el porcentaje de valores nulos que hay en nuestros datos, así como la combinación de valores nulos entre las diferentes dimensiones

```{r na_visualization, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
aggr_plot <- aggr(data_train[,2:7], col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE,
                  labels=names(data_train[,2:7]), cex.axis=.7, gap=3, 
                  ylab=c("Histograma de datos faltantes","Patrones"))
```
Las tres variables con NA son las variables educación (en torno al 4 %) y las variables trabajo y marital, ambas por debajo de 0.01 %. Con este porcentaje de NA, se podría plantear la no imputación de estos.

# Imputación de valores perdidos

```{r impute data_train, warning=FALSE, message=FALSE}
#imputación mucho más lenta que pmm (media)
#impdata_train <- mice(data_train, m=5, maxit = 50, method = 'mean', seed = 1234)
#summary(impdata_train)
#sum(is.na(impdata_train))
#data_train <- impdata_train
```
En estimaciones de valores perdidos, dentro de las estimaciones univariantes, usaremos el método de árbol de regresiones, frente a la media y la moda.



# Análisis exploratorio inicial

El primer paso siempre debe consistir en efectuar un análisis exploratorio de los datos, para empezar a detectar posibles problemas.
```{r eda_inicial, warning=FALSE, message=FALSE, fig.width=12, fig.height=8}

data_train %>% dplyr::select(age,duration,campaign,pdays,previous,emp.var.rate,cons.conf.idx, cons.price.idx,euribor3m,nr.employed,y) %>%
  na.omit() %>%
  ggpairs(columns = 1:9, 
          mapping = ggplot2::aes(colour=y), 
          lower = list(continuous = "points"),
          diag = list(continuous = "densityDiag"),
          upper = list(continuous = "blank"))
```


## Relación entre variables numéricas

```{r cor_plot_numeric, fig.align='center', fig.show='hold', fig.width=12, fig.height=7}
data_trainnum <- select_if(data_train, is.numeric)
cor(data_trainnum)
corPlot(data_trainnum, cex = 0.5, main = "Matriz de correlación", upper = FALSE)
```
Las variables edad, duración y campaña son las tres variables que muestran menor correlación con el resto, por lo que pueden ser variables poco relevantes para el modelo. 

Relativo a la variable previous, observamos que es la única que muestra fundamentalmente correlaciones negativas, por lo que es relevante considerarla en el modelo futuro.


# Transformación de variables cuantitativas

**Días desde el contacto previo**

Antes de nada, se debe comentar que el valor 999 corresponde a gente que nunca se le ha contactado previamente.

```{r density_pdays, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=pdays, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

ggplot(data_train, aes(x=pdays, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)

ggplot(data_train %>% filter(pdays!=999), 
       aes(x=pdays, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

En este caso, parece que hay una concentración muy alta de la gente a la que no se ha contactado nunca dentro de la gente que no ha contratado. Sin embargo, si miramos a la gente que sí que contrata, podemos ver que parece que hay una concentración mayor en las personas que se les contactó entre hace 750 días y "1000" días.

Dado que si tenemos en cuenta a las personas que nunca fueron contactadas el boxplot no es interpretable, plasmamos otro filtrando para que no contengan estos registros. Y nos podemos dar cuenta de que hemos malinterpretado el gráfico de densidad, y que se debe a una alta concentración de valores que nunca han sido contactados. De acuerdo a este último boxplot, la media entre ambos grupos es muy similar, aunque para la gente que no termina contratando los datos son un poco más dispersos.


Dado que es complicado trabajar con un datos numérico de 999 cuando no significa 999, y dado que las ratios de conversión son relativamente similares cuando el valor no es 999, clasificamos a los registros en base a si han sido contactados o no. 

```{r chart_pdays_aux, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
df1 = data_train %>% group_by(y, pdays) %>% summarise(records = n(), .groups = 'drop')
ggplot(df1, aes(fill=y, y=records, x=factor(pdays))) + 
    geom_bar(position="fill", stat="identity")

df1 = data_train %>% mutate(pdays_aux = ifelse(pdays == 999,0,1))
df1 = df1 %>% group_by(y, pdays_aux) %>% summarise(records = n(), .groups = 'drop')

df2 = data_train %>% mutate(pdays_aux = ifelse(pdays == 999,0,1))
df2 = df2 %>% group_by(pdays_aux) %>% summarise(total_records = n())

df3 = df1 %>% left_join(df2, by="pdays_aux") %>% mutate(share = records/total_records)

ggplot(df3 %>% filter(y=='yes'), 
       aes(x=pdays_aux, y=share*40000)) + 
  geom_bar(df2, mapping = aes(x=pdays_aux, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)
```

Los resultados van en línea con lo esperado, teniendo una ratio de conversión más alta la gente que nunca fueron contactados en la campaña anterior 

Binarizacion de la variable pdays. Transformamos la variable numerica pdays a variable binaria que toma valores {0,1}. 
La variable vale 1 si el cliente ha sido contactado anteriormente, 0 en caso contrario
```{r pdays_aux, include=FALSE}
data_train<- data_train %>%
  mutate(pdays_aux=ifelse(pdays=="999",0,1)) 
data_train$pdays_aux<-as.factor(data_train$pdays_aux)
```


# Visualizacion de datos para EDA
## Gráficos para EDA con variables cualitativas individuales

**Trabajo**

```{r histogram_job, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, job) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(job) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="job") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(job, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("job") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por trabajo")
```

Parece que los trabajos que mejor ratio de conversión tienen son los de jubilado, desempleado y estudiante, por lo que job podría ser un buen predictor. Ninguna parece estar relacionada con una forma activa de empleo, lo cual podría indicar la naturaleza del producto financiero ofrecido

Graficamente se observan diferencias significativas entre los  grupos, para comprobar si esto es cierto vamos a hacer un test chi-cuadrado
```{r test chi-cuadrado 1}
tabla1<-table(y,job)
chisq.test(tabla1)
```
Se rechaza la hipótesis nula para cualquier nivel de significancia, luego consideraremos que no hay independencia entre ambas variables, es decir, hay una asociación estadísticamente significativa entre la variable trabajo y la clase y


**Estado civil**

```{r histogram_marital, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, marital) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(marital) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="marital") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(marital, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("marital") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por estado civil")
```

No hay grandes diferencias en la contratación cuando clasificamos a la gente por su estado civil.
Para comprobar si es cierto que no hay diferencias significativas realizamos un test chi-cuadrado
```{r test chi-cuadrado 2}
tabla<-table(y,marital)
chisq.test(tabla)
```
A pesar de lo observado en los gráficos, rechazamos la hipótesis nula para cualquier nivel de significancia. Por lo tanto, consideraremos que no hay independencia entre ambas variables, es decir, existe una asociación estadísticamente significativa entre las variables


**Educación**

```{r histogram_education, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, education) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(education) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="education") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(education, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("education") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por educación")
```

La educación parece que juega también un papel importante en la predicción del éxito de la campaña, siendo university.degree y professional.course las educaciones con mejor ratio de conversión. Por lo que también podría ser un buen predictor

En esta ocasion, para comprobar si es cierto que hay diferencias significativas entre la variable educacion y la clase vamos a hacer un test de Fisher 
El test exacto de Fisher permite analizar si dos variables dicotómicas están asociadas cuando la muestra a estudiar es demasiado pequeña y no se cumplen las condiciones necesarias para que la aplicación del test chi-cuadrado sea adecuada.
```{r test de Fisher}
tabla<-table(y,education)
fisher.test(tabla, simulate.p.value = TRUE, B = 5000)
```
Rechazamos la hipótesis nula, luego consideraremos que no hay independencia entre ambas variables, es decir, hay una asociación estadísticamente significativa entre la educacion y la clase y


**Impago**

```{r histogram_default, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, default) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(default) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="default") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(default, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("default") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por impago")
```

El impago sí que parece un predictor relevante, dado que la gente que no tiene default tiene un ratio de conversión mejor. El valor de unknown podría justificarse con que la gente no quiere decir que hay tenido impagos, y estos impagos podrían implicar una menor capacidad económica y, por tanto, una menor porbabilidad de contratar un producto financiero

Para comprobar si es cierto que hay diferencias significativas vamos a hacer un test de Fisher
```{r test de Fisher 2}
tabla<-table(y,default)
#Con chi-cuadrado daba problemas por lo que uso fisher
fisher.test(tabla)
```
Rechazamos la hipotesis nula, por lo tanto, la variable default presenta una asociacion significativa para la clase y


**Hipoteca**

```{r histogram_housing, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, housing) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(housing) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="housing") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(housing, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("housing") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por hipoteca")
```

No se aprecian diferencias en si el contactado tiene una hipoteca o no

Para comprobar si es cierto que no hay diferencias significativas realizamos un test chi-cuadrado
```{r test chi-cuadrado 3}
tabla<-table(y,housing)
chisq.test(tabla)
chisq.test(tabla, simulate.p.value = TRUE, B = 5000)
```
A pesar de que graficamente no se observan diferencias significativas, al realizar el test chi-cuadrado rechazamos la hipotesis nula, por lo que sí hay una asociacion significativa entre la variable housing y la clase y


**Préstamo**

```{r histogram_loan, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, loan) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(loan) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="loan") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(loan, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("loan") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por préstamo")
```

Tampoco parece haber diferencias teniendo en cuenta si la persona tenía un préstamo o no

Para comprobar si es cierto que hay diferencias significativas vamos a hacer un test chi-cuadrado
```{r test chi cuadrado 4}
tabla<-table(y,loan)
chisq.test(tabla)
chisq.test(tabla, simulate.p.value = TRUE, B = 5000)
```
No hay evidencias significativas para rechazar la hipotesis nula. Por lo tanto, no existen evidencias estadisticamente significativas entra la variable loan y la clase


**Dispositivo de contacto**

```{r histogram_contact, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, contact) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(contact) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="contact") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(contact, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("contact") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por dispositivo de contacto")
```

Parece que la forma de contactar con cada persona podría ser un buen predictor, teniendo el teléfono una ratio de conversión 3 veces superior al teléfono fijo

Para comprobar si es cierto que hay diferencias significativas realizamos el test chi-cuadrado
```{r test chi cuadrado 5}
tabla<-table(y,contact)
chisq.test(tabla)
```
Rechazamos la hipótesis nula para cualquier nivel de significancia. La variable contact presenta una asociación estadísticamente signficativa para y


**Mes de contacto**

```{r histogram_month, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, month) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(month) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="month") %>% mutate(share = records/total_records)

positions <- c("mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec")

ggplot(df3, aes(x = reorder(month, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("month") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por mes de contacto") + 
  scale_x_discrete(limits = positions)
```

El mes también parece un muy buen predictor, habiendo meses como marzo, septiembre, octubre o diciembre, con una ratio de conversión muy alta. Cabe destacar también que son los meses con un menor número de llamadas

Para comprobar si es cierto que hay diferencias significativas vamos a hacer un test chi-cuadrado
```{r test chi cuadrado 6}
tabla<-table(y,month)
chisq.test(tabla)
```
Rechazamos la hipotesis nula, es decir, la variable month muestra una asociación estadísticamente significativa con la clase y


**Día de la semana de contacto**

```{r histogram_day_of_week, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, day_of_week) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(day_of_week) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="day_of_week") %>% mutate(share = records/total_records)

positions <- c("mon", "tue", "wed", "thu", "fri")

ggplot(df3, aes(x = reorder(day_of_week, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("day_of_week") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por día de contacto") + 
  scale_x_discrete(limits = positions)
```

No parece haber ninguna influencia en el resultado de la camapaña por parte del día de la semana de contacto

Para comprobar si es cierto que no hay diferencias significativas vamos a hacer un test chi-cuadrado
```{r test chi cuadrado 7}
tabla<-table(y,day_of_week)
chisq.test(tabla)
```
Rechazamos la hipótesis nula para cualquier nivel de significancia, es decir, existe una asociación significativa entre el día de la semana y la clase y


**Días desde el contacto previo**

```{r histogram_pdays_aux, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, pdays_aux) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(pdays_aux) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="pdays_aux") %>% mutate(share = records/total_records)

ggplot(df3, aes(x=reorder(pdays_aux,-records),y=records, fill=y, ymax=records*1.15)) + 
  geom_bar(stat = "identity", position = "dodge") +
  xlab("pdays_aux") +
  geom_text(stat = "identity", aes(label=paste(records,"\n(", label_percent(accuracy = 1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),size=3) + 
  ggtitle("Distribucion por días desde el contacto previo")
  scale_x_discrete(limits = positions) 
  
```

Observamos que el ratio de conversión más alto es el que corresponde a la gente que nunca fue contactada en la campaña anterior, por lo que la variable que indica si se ha contactado anteriormente con el cliente puede ser un buen predictor

Para comprobar si es cierto que hay diferencias significativas vamos a hacer un test chi-cuadrado
```{r test chi cuadrado 8}
tabla<-table(y,data_train$pdays_aux)
chisq.test(tabla)
```
Rechazamos la hipótesis nula. Por lo tanto, existe una asociación estadísticamente significativa entre la variable pdays_aux y la clase y


**Resultado de la campaña previa**

```{r histogram_poutcome, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y, poutcome) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(poutcome) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="poutcome") %>% mutate(share = records/total_records)

ggplot(df3, aes(x = reorder(poutcome, -records), y=records, fill=y, ymax=records*1.15)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("poutcome") +
  geom_text(stat='identity', aes(label=paste(records, "\n(", label_percent(accuracy=1)(share), ")")), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por el resultado de la campaña previa")
```

El resultado de la campaña previa también puede ser un buen predictor

Para comprobar si es cierto que hay diferencias significativas realizamos un test chi-cuadrado
```{r test chi cuadrado 9}
tabla<-table(y,poutcome)
chisq.test(tabla)
```
Observamos que se rechaza la hipotesis nula para cualquier nivel de significancia, es decir,  poutcome presenta una asociacion estadisticamente significativa con la clase


**Resultado de esta campaña**

```{r histogram_y, warning=FALSE, message=FALSE, fig.width=12, fig.height=3}
df1 = data_train %>% group_by(y) %>% summarise(records = n())

ggplot(df1, aes(x = reorder(y, -records), y=records, fill=y, ymax=records*1.15)
                  ) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("y") +
  geom_text(stat='identity', aes(label=records), vjust=-0.25, position = position_dodge(width = .9),  size=3) + 
  ggtitle("Distribución por el resultado de esta campaña")
```



## Gráficos para EDA con variables cuantitativas individuales

**Edad**

```{r density_age, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=age, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, age) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(age) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="age") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=age, y=share*1500)) + 
  geom_bar(df2, mapping = aes(x=age, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=2)

ggplot(data_train, aes(x=age, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Como podemos observar en la gráfica de densidad, parece que las personas que terminan contratando son ligeramente más mayores que las que no. Y de hecho, como podemos ver en el gráfico de cajas, las edades son de media más bajas y están menos dispersas para las personas que no contratan.

Para comprobar si es cierto que existen evidencias significativas realizamos el test de Student
El llamado test de Student ayuda a determinar si la diferencia observada es o no estadísticamente significativa
```{r test de Student age}
t.test(age~y)
biserial.cor(x = age,  y = y, level = 2)
```
Observando el p-valor sí se consideraría que existen diferencias significativas entre los grupos, por tanto, la edad sí está asociado a y, aunque encontramos que la correlación es relativamente baja.


**Duración de la llamada**

```{r density_duration, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=duration, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

ggplot(data_train, aes(x=duration, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

En este caso, únicamente confirmamos lo que ya sospechábamos, y es que cuanto mayor es la duración de la llamada, mayor es la proporción de personas que termina contratando. La dispersión también es mayor en el caso de la gente que contrata

Para comprobar si es cierto que existen evidencias significativas realizamos el test de Student
```{r test de Student duration}
t.test(duration~y)
```
Sí existe diferencia significativa entre los grupos, por tanto, la duración de la última llamada sí esta asociado a y


**Número de contactos durante esta campaña**

```{r density_campaign, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=campaign, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, campaign) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(campaign) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="campaign") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=campaign, y=share*80000)) + 
  geom_bar(df2, mapping = aes(x=campaign, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)

ggplot(data_train, aes(x=campaign, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Podemos ver que conforme aumentan el número de contactos, la ratio de conversión decrece, lo cual podría indicar que es un buen indicador

Para comprobar si es cierto que existen evidencias significativas realizamos el test de Student
```{r}
t.test(campaign~y)
```
Rechazamos la hipótesis nula para cualquier nivel de significancia por lo que sí se consideraría que existe diferencia significativa entre los grupos. Por lo tanto, campaign sí esta asociado a y


**Número de veces contactado antes de esta campaña**

```{r density_previous, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=previous, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, previous) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(previous) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="previous") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=previous, y=share*40000)) + 
  geom_bar(df2, mapping = aes(x=previous, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)

ggplot(data_train, aes(x=previous, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Parece que la distribución es más o menos similar para ambos grupos de personas, de acuerdo a la función de densidad. Aunque viendo el gráfico de barras apiladas y el gráfico de cajas, parece que hay una mayor concentración de personas que nunca han sido contactadas previamente entre la gente que nunca contrató

Para comprobar si es cierto que existen evidencias significativas realizamos el test de Student
```{r}
t.test(previous~y)
```
Se consideraría que sí existe diferencia significativa entre los grupos, es decir, previous sí esta asociado a y


**Ratio de variación del empleo**

```{r density_emp_var_rate, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=emp.var.rate, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, emp.var.rate) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(emp.var.rate) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="emp.var.rate") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=emp.var.rate, y=share*25000)) + 
  geom_bar(df2, mapping = aes(x=emp.var.rate, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)

ggplot(data_train, aes(x=emp.var.rate, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Parece que cuanto más aumenta el empleo, mayor es la proporción de personas que no termina contratando, lo cual podemos confirmar con el gráfico de cajas. Cuanto más positiva es la variación en el empleo, menos gente contrata, lo cual podría estar relacionado con que la gente tenga menos necesidad de contratar cuando las condiciones macro son mejores

Para comprobar si es cierto que existen evidencias significativas realizamos el test de Student
```{r}
t.test(emp.var.rate~y)
```
El p-valor es inferior a 0.05, rechazamos la hipótesis nula al considerar que sí existe diferencia significativa entre los grupos, es decir, el ratio de variación del empleo sí esta asociado a y


**Índice de precios al consumo**

```{r density_cons_price_idx, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=cons.price.idx, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, cons.price.idx) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(cons.price.idx) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="cons.price.idx") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=cons.price.idx, y=share*12000))  + 
  geom_bar(df2, mapping = aes(x=cons.price.idx, y=total_records), stat = "identity", fill='coral1')+
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)

ggplot(data_train, aes(x=cons.price.idx, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Si miramos la gráfica de densidad, parece que cuando hay un mayor número de registros y el índice aumenta, la ratio de conversión es peor. Es decir, cuando el índice está en mínimos, la ratio es superior.

El gráfico de cajas parece indicar algo parecido, dado que la media del índice es ligeramente superior entre los usuarios que no terminaron contratando, aunque esta diferencia no parece muy relevante.

Para comprobar si es cierto que hay diferencias significativas vamos a hacer un test de Student
```{r}
t.test(cons.price.idx~y)
```
Se consideraría que sí existe diferencia significativa entre los grupos al rechazar la hipótesis nula, por tanto, el índice de precios al consumo sí esta asociado a y


**Índice de confianza del consumidor**

```{r density_cons_conf_idx, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=cons.conf.idx, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, cons.conf.idx) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(cons.conf.idx) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="cons.conf.idx") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=cons.conf.idx, y=share*12000))  + 
  geom_bar(df2, mapping = aes(x=cons.conf.idx, y=total_records), stat = "identity", fill='coral1')+
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)

ggplot(data_train, aes(x=cons.conf.idx, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

La variable Índice de confianza del consumidor tiene un comportamiento similar a la variable Índice de precios al consumo puesto que cuando el índice está en mínimos la ratio es superior.

Para comprobar si es cierto que existen evidencias significativas realizamos el test de Student
```{r}
t.test(cons.conf.idx~y)
```
Al rechazar la hipótesis nula se considera que sí existe diferencia significativa entre los grupos, por tanto, existe una asociación estadísticamente significativa entre el índice de confianza del consumidor y la clase y


**Euribor a 3 meses**

```{r density_euribor3m, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=euribor3m, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

ggplot(data_train, aes(x=euribor3m, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

Cuanto mayor es el euribor, menor cantidad de gente contrata, y viceversa; cuanto menor es, más gente contrata. Esto podría deberse a que un menor euribor implica menores intereses en el producto contratado. El gráfico de cajas nos arroja unos resultados similares

Para comprobar si es cierto que existen evidencias significativas realizamos el test de Student
```{r}
t.test(euribor3m~y)
```
Rechazamos la hipótesis nula para cualquier nivel de significancia, se considera que sí existe diferencia significativa entre los grupos, por tanto, el euribor sí esta asociado a y


**Número de empleados**

```{r density_nr_employed, fig.align='center', fig.show='hold', fig.width=12, fig.height=5}
ggplot(data_train, aes(x=nr.employed, color=y)) +
  geom_density() + 
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(labels = comma)

df1 = data_train %>% group_by(y, nr.employed) %>% summarise(records = n(), .groups = 'drop')
df2 = data_train %>% group_by(nr.employed) %>% summarise(total_records = n())
df3 = df1 %>% left_join(df2, by="nr.employed") %>% mutate(share = records/total_records)
ggplot(df3 %>% filter(y=='yes'), 
       aes(x=nr.employed, y=share*25000)) + 
  geom_bar(df2, mapping = aes(x=nr.employed, y=total_records), stat = "identity", fill='coral1') +
  geom_line(color='chartreuse3') + 
  scale_y_continuous(name='Registros y Porcentaje de contratación') +
  geom_text(stat='identity', aes(label=label_percent(accuracy=1)(share)), vjust=-1.5, position = position_dodge(width = .9),  size=3)

ggplot(data_train, aes(x=nr.employed, y=y)) + 
  geom_boxplot() +
  coord_flip() + 
  geom_jitter(shape=16, position=position_jitter(0.2), size=0.5)
```

A mayor número de emplados, menor es la cantidad de gente que contrata el producto, y viceversa. Esto puede deberse a que conforme mejores son las condiciones macroeconómicas, menor necesidad tiene la gente de contratar este tipo de productos

Para comprobar si es cierto que existen evidencias significativas realizamos el test de Student
```{r}
t.test(nr.employed~y)
```
Se considera que sí existe diferencia significativa entre los grupos al rechzar la hipotesis nula, por tanto, el numero de empleados sí esta asociado a y



# Gráficos para EDA multivariantes

A continuación, vamos a analizar por qué hay determinadas variables que son tan relevantes sin que haya una lógica aparente detrás de ello, como por ejemplo el dispositivo de contacto o el mes de contacto. Y trataremos de averiguar si alguna variable no es relevante por sí sola, sino que depende de otras variables, y poder así reducir variables redundantes

## Gráficos especifico para variables categoricas

**Edad & trabajo**

```{r hist_age_job, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
ggplot(data_train,aes(x=age, fill=job)) + 
  geom_bar() + 
  ggtitle ("Edad y trabajo") + 
  xlab("Edad") + 
  ylab("Trabajo") + 
  labs(fill="y")
```

Vemos que entre los 18 y los 25, la principal ocupación es la de estudiante, hasta los 55, diferentes empleos, y a partir de los 60 la de retirado. Resultados que parecen bastante lógicos.


**Edad y estado civil**

```{r hist_age_marital, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
ggplot(data_train, aes(x=age, fill=marital)) + 
  geom_bar() + 
  ggtitle ("Edad y estado civil") + 
  xlab("Edad") + 
  ylab("Estado civil") + 
  labs(fill="y") 
```

Podemos ver que entre los 18 y los 30, el estado civil predominante es el de soltero, mientras que el de casado, y después el de divorciado, son los más presentes a partir de los 30


**Edad y dispositivo de contacto**

```{r hist_age_contact, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
ggplot(data_train, aes(x=age, fill=contact)) + 
  geom_bar() + 
  ggtitle ("Edad y dispositivo de contacto") + 
  xlab("Edad") + 
  ylab("Dispositivo de contacto") + 
  labs(fill="y") 
```
 
Observamos que por edad, en torno a los 60 años hay menor ratio de conversión por contacto vía teléfono fijo y un descenso abrupto en la cantidad de contactos a personas de esa edad.


**Mes & trabajo**

```{r hist_month_job_1, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
positions <- c("mar", "sep", "oct", "dec")

ggplot(data_train,aes(x=month, fill=job)) + 
  geom_bar() + 
  ggtitle ("Marzo, Septiembre, Octubre y Diciembre: los meses con MEJOR ratio de conversión") + 
  xlab("Edad") + 
  ylab("Trabajo") + 
  labs(fill="y") + 
  scale_x_discrete(limits = positions)
```
```{r hist_month_job_2, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
positions <- c("apr", "may", "jun", "jul", "aug", "nov")

ggplot(data_train,aes(x=month, fill=job)) + 
  geom_bar() + 
  ggtitle ("Abril, Mayo, Junio, Julio, Agosto y Noviembre: los meses con PEOR ratio de conversión") + 
  xlab("Edad") + 
  ylab("Trabajo") + 
  labs(fill="y") + 
  scale_x_discrete(limits = positions)
```

Parece que la principal diferencia entre ambos grupos de meses es la menor presencia de trabajadores blue-collar en el primer grupo, con una mala ratio de conversión, y la mayor presencia de estudiantes y, sobre todo, de gente retirada.

Aún así, debería haber otros factores que afecten a la ratio de conversión tan alta que tienen, dado que es muy superior a la de cualquier trabajo. Por ello, vamos a analizar también la relación con el resultado de campañas anteriores


**Mes & resultado de la campaña previa**

```{r hist_month_poutcome, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
positions <- c("mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec")

df1 = data_train %>% group_by(month, poutcome) %>% summarise(records = n(), .groups = 'drop')
ggplot(df1, aes(fill=poutcome, y=records, x=month)) + 
  geom_bar(position="fill", stat="identity") + 
  scale_x_discrete(limits = positions)+ 
  ggtitle ("Success (65%), Failure (14%) y Nonexistent (9%) (ratios de conversión)") + 
  scale_y_continuous(labels = scales::percent)
```

Parece que también está muy influenciado porque en estos meses la proporción de contactos que en el pasado resultaron en éxito es mucho mayor. De todas formas, parece que es una combinación de varios factores, trabajo, éxito en pasadas campañas..., lo que ha hecho que la ratio en estos meses sea mejor


**Dispositivo de contacto & trabajo**

```{r hist_contact_job, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
df1 = data_train %>% group_by(contact, job) %>% summarise(records = n(), .groups = 'drop')
ggplot(df1, aes(fill=job, y=records, x=contact)) + 
  geom_bar(position="fill", stat="identity") + 
  scale_y_continuous(labels = scales::percent)
```

En este caso, parecen tener mayor relevancia los trabajadores de tipo admin. y technician con una mejor ratio de conversión, y menor los de tipo blue-collar con peor ratio. Como en el caso anterior parece una combinación de varios facores, campaña previa, trabajo..., lo que ha provocado una diferencia en la conversión entre ambas formas de contacto


**Dispositivo de contacto & resultado de la campaña previa**

```{r hist_contact_poutcome, warning=FALSE, message=FALSE, fig.width=12, fig.height=5}
df1 = data_train %>% group_by(contact, poutcome) %>% summarise(records = n(), .groups = 'drop')
ggplot(df1, aes(fill=poutcome, y=records, x=contact)) + 
  geom_bar(position="fill", stat="identity") + 
  ggtitle ("Success (65%), Failure (14%) y Nonexistent (9%) (ratios de conversión)") + 
  scale_y_continuous(labels = scales::percent)
```

Podemos ver que success y failure tienen mayor peso en los contactado por teléfono, los cuales tienen una mejor ratio de conversión


# Modelos de regresión logística

Debido a que la variable y (compra o no el producto tras la llamada), es binaria, no se puede plantear la regresión lineal. Por tanto, se plantea un modelo de regresión logística.

Previo a la aplicación del modelo, convertimos los valores en 0 y 1, tanto del train como del test.

```{r test_pdays_aux}
df1 = data_test %>% group_by(y, pdays) %>% summarise(records = n(), .groups = 'drop')
data_test = data_test %>% mutate(pdays_aux = ifelse(pdays == 999,0,1))
```

```{r}
data_train$y <- as.numeric(data_train$y)
data_train$y[which(data_train$y =="1")] <- 0
data_train$y[which(data_train$y =="2")] <- 1
``` 

```{r}
data_test$y[which(data_test$y =="no")] <- 0
data_test$y[which(data_test$y =="yes")] <- 1
data_test$y <- as.numeric(data_test$y)
```
## Técnicas automáticas de selección de variables

**Forward Stepwise**
```{r}
regfit_fwd <- leaps::regsubsets(y~., data_train, method="forward")
for (metric in c("r2", "adjr2", "Cp", "bic")){plot(regfit_fwd, scale=metric)}
```
Las variables relevantes para obtener el modelo con mejor ajuste y redimiento obtenidas por el método forward serían mes (abril, mayo y noviembre), duración de la llamada, días previos, poutcome, cons.conf.idx y número de empleados.

**Backward Stepwise**
```{r}
regfit_bwd <- leaps::regsubsets(y~., data_train, method="backward")
for (metric in c("r2", "adjr2", "Cp", "bic")){plot(regfit_bwd, scale=metric)}
```
Las variables relevantes para obtener el modelo con mejor ajuste y redimiento obtenidas por el método backward serían mes (abril, mayo, junio y octubre), duración de la llamada, poutcome, emp.var.rate y cons.price.idx. 

Ambos métodos sugieren como variables relevantes comunes el mes, la duración de la llamada y el resultado de la campaña previa.

## Modelos

```{r}
#m0 <- glm(y ~1, data = data_train, family = "binomial")
m1 <- glm(y ~ ., data = data_train, family = "binomial")
```

El modelo 1 corresponde al modelo con todas las variables.

*Variables significativas del modelo completo*
```{r}
sig.var<- summary(m1)$coeff[-1,4] <0.01
names(sig.var)[sig.var == TRUE]
```


Por tanto, las variables significativas del modelo son el trabajo (jubilado), educación (universidad), dispositivo de contacto (teléfono), mes de contacto (abril, mayo, junio, julio, agosto, septiembre, octubre, noviembre y diciembre), día de la semana de contacto (martes, miércoles y jueves), duración, días desde el contacto previo, número de contactos durante esta campaña, ratio de variación del empleo, índice de precios al consumo, índice de confianza del consumidor y el número de empleados. La duración de la llamada no se considera relevante, ya que se obtiene después de haber realizado la transacción. Esta variable, al tener una alta correlación con la variable de salida, infraestima los valores de error y sobrestima el ajuste. Con esto, creamos el modelo 8 con todas las variables significativas del modelo completo, menos la duración de la llamada. 

```{r}
m2 <- glm(y ~ age, data = data_train, family = "binomial")
m3 <- glm(y ~ emp.var.rate, data = data_train, family = "binomial")
#modelo forward
m4 <- glm(y ~ month+pdays+poutcome+cons.conf.idx+nr.employed, data = data_train, family = "binomial")
#modelo backward
m5 <- glm(y ~ month+poutcome+emp.var.rate+cons.price.idx, data = data_train, family = "binomial")
#modelo comunes back y forward.
m6 <- glm(y ~ month+duration+poutcome, data = data_train, family = "binomial")
#modelo comunes back y forward sin duración 
m7 <- glm(y ~ month+poutcome, data = data_train, family = "binomial")
```

Los modelos 2 y 3 son modelos con la variable que menos correlaciona (edad) y la que más correlaciona con el resto (tasa de variación de empleo).
El modelo 4 y 5 corresponden a los métodos automáticos de forward y backward.
El modelo 6 corresponde a las variables comunes entre los métodos automáticos de forward y backward.
El modelo 7 es igual que el modelo 6, sin la variable duración de la llamada.


```{r}
m8 <- glm(y ~ job+education+default+contact+month+campaign+pdays+poutcome+emp.var.rate+cons.price.idx+cons.conf.idx+nr.employed, family = binomial, data= data_train)
summary(m8)
#Método manual
m9 <- glm(y ~ month + pdays_aux + poutcome + euribor3m, data = data_train, family = binomial)
```

**Supuestos de partida para regresión**

Obtenemos la homogeneidad de la varianza, la colinealidad y la normalidad de los residuos, ya que son los supuestos de partida para aplicar la regresión logística 

```{r}
#check_model(m0)
check_model(m1)
check_model(m2)
check_model(m3)
check_model(m4)
```
El modelo 1 tiene valores muy altos de colinealidad, coherente con el uso de variables muy correlacionadas como mencionamos previamente. pero valores adecuados de 
Los modelos 2 y 3 no muestra la gráfica de colinealidad por tener un solo predictor. El modelo 4 muestra valores bajos de colinealidad.

Ninguno de estos 4 modelos muestra valores adecuados en la normalidad de los residuos, en el gráfico Q-Q. Los puntos se encuentran en los modelos dentro del intervalo marcado por la distancia D de Cook

```{r}
check_model(m5)
check_model(m6)
check_model(m7)
check_model(m8)
check_model(m9)
```
Los modelos 5,6 y 7 muestran valores bajos de colinealidad, frente al último que tiene valores muy altos, aumentando el riesgo de sesgo. La normalidad en el gráfico Q-Q son similares entre modelos, siendo la más diferente en el modelo 5. Aunque los valores de leverage son altos, el único modelo en el que se ajusta es el modelo 8

```{r}
compare_performance(m1,m2,m3,m4,m5,m6,m7,m8,m9)
``` 

Los modelos muestran valores altos de AIC y BIC en general, siendo índices de ajuste de parsimonia, sancionando modelos que requieren un mayor número de variables. Los menores valores son del modelo 1, pero incluye todas las variables (también la variable duración, una variable que no será útil puesto que la obtenemos tras la realización de la llamada). Lo mismo ocurre con el modelo 6, obteniendo valores ligeramente más bajos de AIC y BIC, y de RMSE, así como de $R^2$ de Tjur o el coeficiente D de determinación para variables binarias  El modelo 8 será el seleccionado, debido a la información extra y al aumento del valor de 


```{r}
plot(compare_performance(m1,m2,m3,m4,m5,m6,m7,m8,m9, rank = TRUE))
```

Gráficamente, podemos evaluar que cuanto más cercano del centro, mejor rendimiento muestra. El objetivo es reducir AIC, BIC y RMSE y aumentar el $R^2$. 

### Modelo 1. Modelo completo

```{r}
Box.test(residuals(m1),type="Ljung-Box")
```
Hay presencia de autocorrelación, lo que podría sesgar el modelo.


*Predicciones y matriz de confusión del modelo completo (m1)*

```{r}
predicciones <- ifelse(test = m1$fitted.values > 0.5, yes = 1, no = 0)
matriz_confusion <- table(m1$model$y, predicciones,
                          dnn = c("observaciones", "predicciones"))
matriz_confusion
```
```{r}
TN <- matriz_confusion[1,1]
FP <- matriz_confusion[1,2]
FN <- matriz_confusion[2,1]
TP <- matriz_confusion[2,2]
```

Se observa una mejor ratio de TN que de TP.

*Medidas de clasificación del modelo completo (m1)*

```{r}
precision <- TP/(TP+FP)
recall <- TP/(TP+FN)
F1 <- 2*(precision*recall)/(precision+recall)
accuracy <- (TP+TN)/(TP+TN+FP+FN)
tabla1 <- matrix(data = c(precision,recall,F1,accuracy), ncol=1, nrow=4)
rownames(tabla1) <- c("Precision","Recall","F1","Accuracy")
tabla1
```

```{r}
mosaic(matriz_confusion, shade = T, colorize = T,
       gp = gpar(fill = matrix(c("green3", "red2", "red2", "green3"), 2, 2)))
``` 

```{r}
data_test$pdays_aux <- as.factor(data_test$pdays_aux)
pred1<- predict.glm(m1,newdata = data_test, type="response")
result1<- table(data_test$y, floor(pred1+0.5))
result1
```

*Evaluación del modelo completo (m1)*

**Curva ROC**

Realizamos la curva ROC para evaluar el AUC del modelo.

```{r}
ROC <- roc(data_test$y, pred1)
plot(ROC, col = "red")
auc(ROC)
logistic_gains_table1 <- blr_gains_table(m1, data = data_train)
blr_roc_curve(logistic_gains_table1)
```

El AUC tiene un valor muy adecuado. Sin embargo, analizaremos un modelo más parsimonioso que el modelo completo. 

**Lift chart y KS Chart**

```{r}
logistic_gains_table <- blr_gains_table(m1, data = data_train)
blr_decile_lift_chart(logistic_gains_table)
blr_ks_chart(logistic_gains_table)
```
El lift chart muestra... el KS chart muestra una estructura similar a la curva ROC.

### Modelo final seleccionado. Modelo 8.

```{r}
Box.test(residuals(m8),type="Ljung-Box")
```
Hay presencia de autocorrelación, lo que podría sesgar el modelo.


*Predicciones y matriz de confusión del modelo final (m8)*

```{r}
predicciones1 <- ifelse(test = m8$fitted.values > 0.5, yes = 1, no = 0)
matriz_confusion1 <- table(m8$model$y, predicciones1,
                          dnn = c("observaciones", "predicciones"))
matriz_confusion1
```

```{r}
TN1 <- matriz_confusion1[1,1]
FP1 <- matriz_confusion1[1,2]
FN1 <- matriz_confusion1[2,1]
TP1 <- matriz_confusion1[2,2]
```

Se observa una mejor ratio de TN que de TP.

*Medidas de clasificación*
```{r}
precision1 <- TP1/(TP1+FP1)
recall1 <- TP1/(TP1+FN1)
F11 <- 2*(precision1*recall1)/(precision1+recall1)
accuracy1 <- (TP1+TN1)/(TP1+TN1+FP1+FN1)
tabla11 <- matrix(data = c(precision1,recall1,F11,accuracy1), ncol=1, nrow=4)
rownames(tabla11) <- c("Precision","Recall","F1","Accuracy")
tabla11
```

```{r}
mosaic(matriz_confusion1, shade = T, colorize = T,
       gp = gpar(fill = matrix(c("green3", "red2", "red2", "green3"), 2, 2)))
``` 

```{r}
pred11<- predict.glm(m8,newdata = data_test, type="response")
result11<- table(data_test$y, floor(pred11+0.5))
result11
```

**Curva ROC**

Realizamos la curva ROC para evaluar el AUC del modelo.

```{r}
ROC1 <- roc(data_test$y, pred11)
plot(ROC1, col = "red")
auc(ROC1)
logistic_gains_table11 <- blr_gains_table(m8, data = data_train)
blr_roc_curve(logistic_gains_table11)
```

El AUC tiene un valor más bajo que el modelo completo.

**Lift chart y KS Chart**

```{r}
logistic_gains_table1 <- blr_gains_table(m8, data = data_train)
blr_decile_lift_chart(logistic_gains_table1)
blr_ks_chart(logistic_gains_table1)
```
El KS se ha reducido significativamente frente al modelo completo.

***Conclusiones del ajuste*** 

El ajuste en general, así como las predicciones han de ser tomadas con cautela debido a los supuestos de partida de la regresión logística.
Los modelos de regresión logística muestran un ajuste pobre, quedando claro que la variable duración aumenta articialmente el ajuste. En general, el modelo completo (m1) es el modelo que ajusta mejor. 

Con otros modelos obtenemos valores ligeramente peores, pero son mucho más parsimoniosos. 
